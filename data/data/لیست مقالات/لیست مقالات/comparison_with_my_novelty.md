Based on your **two novelties** (from `merged_novelties.md`):

1. **Shallowâ€“Deep Similarity + Beyond-Episode Memory (SDSimPoint-style idea)**
2. **Dynamic Edge-Driven Graph Connectivity (edgeâ†’node adaptive topology learning)**

and after carefully examining the four candidate articles:

* **SGE**
* **FSAKE**
* **MKGPL**
* **MPCF**

I will now give you a **clear, research-level recommendation** about which one is the strongest baseline for your novelties.

---

# ğŸ” Step 1 â€” Match Each Paper Against Your Two Novelties

We evaluate structural alignment, not just topic similarity.

---

# 1ï¸âƒ£ SGE (Semantic-Guided Generalization Enhancement)

### What it does:

* Uses CLIP + Stable Diffusion
* Cross-domain alternating training
* Semantic-guided augmentation
* Feature fusion at test time

### Alignment with Your Novelties:

| Your Novelty                           | Alignment with SGE         |
| -------------------------------------- | -------------------------- |
| Shallowâ€“Deep similarity separation    | âŒ Not present             |
| Deep semantic modeling via interaction | âš ï¸ Only via text prompts |
| Memory beyond episode                  | âŒ No                      |
| Dynamic graph connectivity             | âŒ No                      |
| Edge-driven topology                   | âŒ No                      |

### Verdict:

SGE is **semantic augmentation based**, not structural similarity modeling.
It is **conceptually different** from your work.

ğŸ‘‰ **Not a good structural baseline.**

---

# 2ï¸âƒ£ FSAKE (Few-shot Adaptive Neighbor Knowledge Embedding)

### What it does:

* Graph-level few-shot learning
* Neighbor-aware knowledge filtering
* Adaptive pooling
* Knowledge correction loss
* Uses Graph U-Net

### Alignment with Your Novelties:

| Your Novelty                       | Alignment with FSAKE              |
| ---------------------------------- | --------------------------------- |
| Graph structure modeling           | âœ… Yes                            |
| Neighbor-aware reasoning           | âœ… Yes                            |
| Structural adaptation              | âš ï¸ Semi-dynamic (pooling-based) |
| Edge feature modeling              | âŒ No                             |
| Dynamic adjacency update per layer | âŒ No                             |
| Edgeâ†’node message passing         | âŒ No                             |
| Similarity taxonomy (shallow/deep) | âŒ No                             |

### Key Insight:

FSAKE:

* Uses **graph pooling**
* Still relies on node-based message passing
* Graph structure is not rebuilt dynamically via learned edge embeddings

Your novelty:

* Reconstructs adjacency from learned edge features
* Edge-driven topology learning
* Dynamic connectivity
* Potential variable degree graph

This is **strictly more advanced than FSAKE structurally**.

### Verdict:

ğŸ‘‰ **Best baseline for your Dynamic Graph Connectivity novelty.**

It is the closest structural neighbor in the literature.

---

# 3ï¸âƒ£ MKGPL (Graph Prompt Learning with Multi-View Knowledge)

### What it does:

* Positive text graph
* Negative text graph
* Image graph
* Graph prompts
* Multi-view fusion

### Alignment with Your Novelties:

| Your Novelty                       | Alignment             |
| ---------------------------------- | --------------------- |
| Graph modeling                     | âœ… Yes                |
| Multi-view semantic similarity     | âš ï¸ Yes (text-based) |
| Dynamic topology                   | âŒ No                 |
| Edge-driven updates                | âŒ No                 |
| Similarity taxonomy (shallow/deep) | âŒ Not explicit       |
| Cross-episode memory               | âŒ No                 |

MKGPL is:

* Graph-structured prompt learning
* Focused on positive/negative semantics
* Based on CLIP adaptation

Your method is:

* Structural graph learning
* Edge-featureâ€“driven topology evolution
* Dynamic rewiring

Conceptual gap is large.

ğŸ‘‰ Not a suitable baseline for structural novelty.

---

# 4ï¸âƒ£ MPCF (Multimodal Prototypical Networks with Co-Metric Fusion)

### What it does:

* Image + text prototypes
* Contrastive alignment
* Weighted metric fusion
* Cross-domain few-shot HSI

### Alignment:

| Your Novelty             | Alignment           |
| ------------------------ | ------------------- |
| Similarity modeling      | âœ… Yes              |
| Deep semantic fusion     | âš ï¸ Yes (via text) |
| Shallowâ€“deep separation | âŒ No               |
| Graph modeling           | âŒ No               |
| Dynamic connectivity     | âŒ No               |
| Edge modeling            | âŒ No               |

This is metric fusion, not structural innovation.

ğŸ‘‰ Not a structural baseline.

---

# ğŸ† Final Ranking (Best Baseline for Your Work)

| Rank | Paper           | Suitability |
| ---- | --------------- | ----------- |
| ğŸ¥‡ 1 | **FSAKE** | â­â­â­â­â­  |
| ğŸ¥ˆ 2 | MKGPL           | â­â­        |
| ğŸ¥‰ 3 | MPCF            | â­          |
| âŒ 4 | SGE             | âŒ          |

---

# ğŸ¯ Final Answer

## âœ… **FSAKE should be used as the baseline for your novelties.**

Here is why:

### 1ï¸âƒ£ It is graph-based few-shot learning.

Your second novelty is fundamentally a graph innovation.

### 2ï¸âƒ£ It performs structural reasoning.

But:

* It uses static adjacency.
* It does not learn edge features explicitly.
* It does not reconstruct topology dynamically.

Your method **strictly generalizes and improves over FSAKE**.

---

# ğŸ”¬ How You Should Position Your Novelty Against FSAKE

In a paper, you can claim:

> While FSAKE improves node importance selection using neighbor-aware filtering and correction supervision, it relies on fixed graph connectivity and node-centric message passing. In contrast, our method introduces an edge-featureâ€“driven dynamic topology learning mechanism that reconstructs graph structure adaptively at each layer, enabling edge-centric relational modeling and variable-degree connectivity.

That is a strong novelty positioning.

---

# ğŸ“Œ What About Your Shallowâ€“Deep Similarity Novelty?

If you are positioning that one:

None of the four papers explicitly model similarity taxonomy.

So:

* You could compare against FSAKE structurally.
* But your shallowâ€“deep similarity novelty is orthogonal to all four.

---

# ğŸ§  Strategic Advice

If your goal is:

### ğŸŸ¢ Publishing in a graph-oriented journal:

Use **FSAKE** as baseline.

### ğŸŸ¢ Publishing in a multimodal/semantic journal:

Then MKGPL or MPCF might be comparison references, but not baselines.

---

# ğŸ Final Conclusion

âœ” For your **Dynamic Graph Connectivity novelty â†’ FSAKE is the correct baseline.**

âœ” For your **Shallowâ€“Deep Similarity novelty â†’ none of the four is a direct baseline**, but FSAKE remains the closest structural comparison.

---

If you want, I can next:

* Help you write the exact â€œBaseline Justificationâ€ paragraph for your paper.
* Or analyze whether combining both of your novelties makes the contribution stronger than FSAKE-level novelty.
