# ── Section 13: Evaluation & Statistical Testing ─────────────────────────────
from scipy import stats as scipy_stats

def evaluate(model: DEKAEModel, episode_fn, n_way: int, k_shot: int,
             n_query: int, n_episodes: int = 1000) -> dict:
    """
    Evaluate over n_episodes test episodes.
    Returns accuracy mean, 95% CI, and full per-episode result dict.
    """
    model.eval()
    accs, densities, avg_degrees = [], [], []
    intra_ratios, inter_ratios   = [], []
    # intra_ratios tracked explicitly for Group D avg_intra_ratio reporting

    with torch.no_grad():
        for _ in tqdm(range(n_episodes), desc="Evaluating"):
            s_imgs, s_lbl, q_imgs, q_lbl = episode_fn(n_way, k_shot, n_query)
            s_imgs = s_imgs.to(DEVICE)
            s_lbl  = s_lbl.to(DEVICE)
            q_imgs = q_imgs.to(DEVICE)
            q_lbl  = q_lbl.to(DEVICE)

            logits, _, mets = model(s_imgs, s_lbl, q_imgs)
            preds = logits.argmax(dim=1)
            acc   = (preds == q_lbl).float().mean().item()
            accs.append(acc)
            densities.append(mets["graph_density"])
            avg_degrees.append(mets["avg_degree"])
            intra_ratios.append(mets.get("intra_edge_ratio", 0.0))

    accs_np  = np.array(accs)
    mean_acc = accs_np.mean()
    ci_95    = 1.96 * accs_np.std() / (len(accs_np) ** 0.5)

    return {
        "mean_acc"             : mean_acc,
        "ci_95"                : ci_95,
        "per_episode"          : accs,
        "avg_density"          : np.mean(densities),
        "avg_degree"           : np.mean(avg_degrees),
        "per_episode_density"  : densities,   # Group D: topology_stability per seed
        "avg_intra_ratio"      : np.mean(intra_ratios) if intra_ratios else 0.0,
    }


def paired_ttest(accs_a: list, accs_b: list) -> dict:
    """
    Paired t-test between two models across the same episodes.
    Returns t-statistic and p-value. p < 0.05 → significant improvement.
    """
    t_stat, p_val = scipy_stats.ttest_rel(accs_b, accs_a)
    return {"t_statistic": t_stat, "p_value": p_val,
            "significant_at_0.05": p_val < 0.05}


def compute_intra_inter_edge_ratio(A: torch.Tensor, labels: torch.Tensor):
    """
    Given an adjacency matrix and node labels, compute the ratio of
    intra-class and inter-class edges (for graph quality reporting).
    """
    N = A.size(0)
    intra = inter = 0
    for i in range(N):
        for j in range(N):
            if i != j and A[i, j] > 0:
                if labels[i] == labels[j]:
                    intra += 1
                else:
                    inter += 1
    total = intra + inter
    return intra / max(total, 1), inter / max(total, 1)


# ── Example usage (illustrative — replace dummy episode_fn with real loader) ──
def _dummy_episode_fn(n_way, k_shot, n_query):
    """Placeholder using synthetic data — replace with real dataset loader."""
    s_imgs  = torch.randn(n_way * k_shot,  3, 84, 84)
    s_lbl   = torch.repeat_interleave(torch.arange(n_way), k_shot)
    q_imgs  = torch.randn(n_way * n_query, 3, 84, 84)
    q_lbl   = torch.repeat_interleave(torch.arange(n_way), n_query)
    return s_imgs, s_lbl, q_imgs, q_lbl

_eval_result = evaluate(_model, _dummy_episode_fn, n_way=5, k_shot=1,
                        n_query=15, n_episodes=50)
print(f"Accuracy: {_eval_result['mean_acc']*100:.2f} ± "
      f"{_eval_result['ci_95']*100:.2f}% (95% CI)")
print(f"Avg density: {_eval_result['avg_density']:.3f}")