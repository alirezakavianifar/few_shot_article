{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4e915e4e",
      "metadata": {
        "id": "4e915e4e"
      },
      "source": [
        "# DEKAE: Dynamic Edge-driven Topology for Episodic Few-Shot Learning\n",
        "## Extension of FSAKE with Supervised Relational Recovery\n",
        "\n",
        "**Paper identity**: *A topology-learning framework with explicit structural regularization and supervised relational recovery for episodic few-shot learning.*\n",
        "\n",
        "| Section | Description |\n",
        "|---------|-------------|\n",
        "| 1 | Environment Setup & GPU Check |\n",
        "| 2 | Google Drive Mount & Data Pipeline |\n",
        "| 3 | Dataset & Episodic Loader |\n",
        "| 4 | Backbone (Conv4) |\n",
        "| 5 | Static k-NN Graph Module (FSAKE Baseline) |\n",
        "| 6 | Edge Incidence Matrix & Dynamic Edge Features |\n",
        "| 7 | Adaptive Topology Reconstruction |\n",
        "| 8 | Knowledge Filtering with Edge Awareness |\n",
        "| 9 | Supervised Edge Loss (Support-Support Only) |\n",
        "| 10 | Sparsity Regularization |\n",
        "| 11 | Full Model Assembly (DEKAE) |\n",
        "| 12 | Training Loop with Checkpointing |\n",
        "| 13 | Evaluation & Statistical Testing |\n",
        "| 14 | Synthetic Graph Recovery Experiment |\n",
        "| 15 | Ablation Study Runner |\n",
        "| 16 | Metrics Logging (W&B) |\n",
        "| 17 | Visualization Suite |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e7ff035",
      "metadata": {
        "id": "6e7ff035"
      },
      "source": [
        "## Section 1: Environment Setup & Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f14ec4f2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f14ec4f2",
        "outputId": "37332087-7b20-41bf-b379-2f0fcda24d09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/learn2learn\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.12/dist-packages (from learn2learn==0.2.1) (2.0.2)\n",
            "Requirement already satisfied: gym>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from learn2learn==0.2.1) (0.25.2)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from learn2learn==0.2.1) (2.10.0+cu128)\n",
            "Requirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from learn2learn==0.2.1) (0.25.0+cu128)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from learn2learn==0.2.1) (1.16.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from learn2learn==0.2.1) (2.32.4)\n",
            "Requirement already satisfied: gsutil in /usr/local/lib/python3.12/dist-packages (from learn2learn==0.2.1) (5.35)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from learn2learn==0.2.1) (4.67.3)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gym>=0.14.0->learn2learn==0.2.1) (3.1.2)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.12/dist-packages (from gym>=0.14.0->learn2learn==0.2.1) (0.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->learn2learn==0.2.1) (3.24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->learn2learn==0.2.1) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->learn2learn==0.2.1) (69.5.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->learn2learn==0.2.1) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->learn2learn==0.2.1) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->learn2learn==0.2.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->learn2learn==0.2.1) (2025.3.0)\n",
            "Requirement already satisfied: cuda-bindings==12.9.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->learn2learn==0.2.1) (12.9.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->learn2learn==0.2.1) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->learn2learn==0.2.1) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->learn2learn==0.2.1) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->learn2learn==0.2.1) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->learn2learn==0.2.1) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->learn2learn==0.2.1) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->learn2learn==0.2.1) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->learn2learn==0.2.1) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->learn2learn==0.2.1) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->learn2learn==0.2.1) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->learn2learn==0.2.1) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->learn2learn==0.2.1) (3.4.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->learn2learn==0.2.1) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->learn2learn==0.2.1) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->learn2learn==0.2.1) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.6.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->learn2learn==0.2.1) (3.6.0)\n",
            "Requirement already satisfied: cuda-pathfinder~=1.1 in /usr/local/lib/python3.12/dist-packages (from cuda-bindings==12.9.4->torch>=1.1.0->learn2learn==0.2.1) (1.3.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision>=0.3.0->learn2learn==0.2.1) (11.3.0)\n",
            "Requirement already satisfied: argcomplete>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from gsutil->learn2learn==0.2.1) (3.6.3)\n",
            "Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python3.12/dist-packages (from gsutil->learn2learn==0.2.1) (1.7)\n",
            "Requirement already satisfied: fasteners>=0.14.1 in /usr/local/lib/python3.12/dist-packages (from gsutil->learn2learn==0.2.1) (0.20)\n",
            "Requirement already satisfied: gcs-oauth2-boto-plugin>=3.3 in /usr/local/lib/python3.12/dist-packages (from gsutil->learn2learn==0.2.1) (3.3)\n",
            "Requirement already satisfied: google-apitools>=0.5.32 in /usr/local/lib/python3.12/dist-packages (from gsutil->learn2learn==0.2.1) (0.5.35)\n",
            "Requirement already satisfied: httplib2==0.20.4 in /usr/local/lib/python3.12/dist-packages (from gsutil->learn2learn==0.2.1) (0.20.4)\n",
            "Requirement already satisfied: google-reauth>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from gsutil->learn2learn==0.2.1) (0.1.1)\n",
            "Requirement already satisfied: monotonic>=1.4 in /usr/local/lib/python3.12/dist-packages (from gsutil->learn2learn==0.2.1) (1.6)\n",
            "Requirement already satisfied: pyOpenSSL<=24.2.1,>=0.13 in /usr/local/lib/python3.12/dist-packages (from gsutil->learn2learn==0.2.1) (24.2.1)\n",
            "Requirement already satisfied: retry-decorator>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from gsutil->learn2learn==0.2.1) (1.1.1)\n",
            "Requirement already satisfied: six>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from gsutil->learn2learn==0.2.1) (1.17.0)\n",
            "Requirement already satisfied: google-auth==2.39.0 in /usr/local/lib/python3.12/dist-packages (from google-auth[aiohttp]==2.39.0->gsutil->learn2learn==0.2.1) (2.39.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from gsutil->learn2learn==0.2.1) (0.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth==2.39.0->google-auth[aiohttp]==2.39.0->gsutil->learn2learn==0.2.1) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth==2.39.0->google-auth[aiohttp]==2.39.0->gsutil->learn2learn==0.2.1) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth==2.39.0->google-auth[aiohttp]==2.39.0->gsutil->learn2learn==0.2.1) (4.7.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from google-auth[aiohttp]==2.39.0->gsutil->learn2learn==0.2.1) (3.13.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.12/dist-packages (from httplib2==0.20.4->gsutil->learn2learn==0.2.1) (3.3.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->learn2learn==0.2.1) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->learn2learn==0.2.1) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->learn2learn==0.2.1) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->learn2learn==0.2.1) (2026.1.4)\n",
            "Requirement already satisfied: boto>=2.29.1 in /usr/local/lib/python3.12/dist-packages (from gcs-oauth2-boto-plugin>=3.3->gsutil->learn2learn==0.2.1) (2.49.0)\n",
            "Requirement already satisfied: oauth2client>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from gcs-oauth2-boto-plugin>=3.3->gsutil->learn2learn==0.2.1) (4.1.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from rsa<5,>=3.1.4->google-auth==2.39.0->google-auth[aiohttp]==2.39.0->gsutil->learn2learn==0.2.1) (0.6.2)\n",
            "Requirement already satisfied: pyu2f in /usr/local/lib/python3.12/dist-packages (from google-reauth>=0.1.0->gsutil->learn2learn==0.2.1) (0.1.5)\n",
            "Requirement already satisfied: cryptography<44,>=41.0.5 in /usr/local/lib/python3.12/dist-packages (from pyOpenSSL<=24.2.1,>=0.13->gsutil->learn2learn==0.2.1) (43.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.1.0->learn2learn==0.2.1) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.1.0->learn2learn==0.2.1) (3.0.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.6.2->google-auth[aiohttp]==2.39.0->gsutil->learn2learn==0.2.1) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.6.2->google-auth[aiohttp]==2.39.0->gsutil->learn2learn==0.2.1) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.6.2->google-auth[aiohttp]==2.39.0->gsutil->learn2learn==0.2.1) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.6.2->google-auth[aiohttp]==2.39.0->gsutil->learn2learn==0.2.1) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.6.2->google-auth[aiohttp]==2.39.0->gsutil->learn2learn==0.2.1) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.6.2->google-auth[aiohttp]==2.39.0->gsutil->learn2learn==0.2.1) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.6.2->google-auth[aiohttp]==2.39.0->gsutil->learn2learn==0.2.1) (1.22.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography<44,>=41.0.5->pyOpenSSL<=24.2.1,>=0.13->gsutil->learn2learn==0.2.1) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography<44,>=41.0.5->pyOpenSSL<=24.2.1,>=0.13->gsutil->learn2learn==0.2.1) (3.0)\n",
            "Installing collected packages: learn2learn\n",
            "  Attempting uninstall: learn2learn\n",
            "    Found existing installation: learn2learn 0.2.1\n",
            "    Uninstalling learn2learn-0.2.1:\n",
            "      Successfully uninstalled learn2learn-0.2.1\n",
            "  Running setup.py develop for learn2learn\n",
            "Successfully installed learn2learn-0.2.1\n",
            "PyTorch version : 2.10.0+cu128\n",
            "CUDA available  : True\n",
            "GPU             : NVIDIA RTX PRO 6000 Blackwell Server Edition\n",
            "VRAM            : 101.97 GB\n",
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "# ── Section 1: Environment Setup & Dependencies ──────────────────────────────\n",
        "# Run once per Colab session. Installs torch-geometric matching the Colab CUDA version.\n",
        "\n",
        "import sys\n",
        "import torch\n",
        "import os\n",
        "\n",
        "# 1. Downgrade setuptools to avoid build errors with older packages\n",
        "!pip install -q \"setuptools<70\" wheel Cython\n",
        "\n",
        "# 2. Install standard dependencies\n",
        "!pip install -q torch-geometric wandb scipy scikit-learn matplotlib seaborn networkx tqdm Pillow\n",
        "\n",
        "# 3. Install learn2learn from source in editable mode (bypasses wheel build failure)\n",
        "if not os.path.exists(\"learn2learn\"):\n",
        "    !git clone https://github.com/learnables/learn2learn.git\n",
        "\n",
        "# Install with -e (editable) to skip bdist_wheel\n",
        "!cd learn2learn && pip install -e .\n",
        "\n",
        "print(\"PyTorch version :\", torch.__version__)\n",
        "print(\"CUDA available  :\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU             :\", torch.cuda.get_device_name(0))\n",
        "    print(\"VRAM            :\", round(torch.cuda.get_device_properties(0).total_memory / 1e9, 2), \"GB\")\n",
        "else:\n",
        "    print(\"⚠ No GPU detected — switch Runtime → Change runtime type → GPU\")\n",
        "\n",
        "# ── Reproducibility ───────────────────────────────────────────────────────────\n",
        "import random, numpy as np\n",
        "\n",
        "GLOBAL_SEED = 42\n",
        "\n",
        "def set_seed(seed: int = GLOBAL_SEED):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed()\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ae8378c",
      "metadata": {
        "id": "0ae8378c"
      },
      "source": [
        "## Section 2: Google Drive Mount & Data Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "cd7665eb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd7665eb",
        "outputId": "33d74573-8690-41cd-ec75-a1776bbc74ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "learn2learn imported from: /content/learn2learn/learn2learn/__init__.py\n",
            "Downloading / loading cifarFS …\n",
            "cifarFS — train: 64 classes, val: 16 classes, test: 20 classes\n",
            "Data stored at : /content/data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not running on Colab — Drive fallback at: /tmp/FSAKE_Project\n",
            "CKPT dir    : /tmp/FSAKE_Project/checkpoints\n",
            "Results dir : /tmp/FSAKE_Project/results\n"
          ]
        }
      ],
      "source": [
        "# ── Section 2: Data Download + Google Drive Setup ────────────────────────────\n",
        "# Strategy:\n",
        "#   • Datasets are downloaded automatically via learn2learn (no manual work).\n",
        "#   • Downloaded data lives on /content/data  (fast local SSD).\n",
        "#   • Checkpoints & results are saved to Google Drive so they survive\n",
        "#     session disconnects.\n",
        "#\n",
        "# Supported datasets (all download automatically on first run):\n",
        "#   ACTIVE_DATASET = 'miniImageNet'   ← change to switch dataset\n",
        "#   Other options : 'tieredImageNet' | 'cifarFS' | 'cub'\n",
        "\n",
        "import shutil, pathlib, zipfile, sys, os\n",
        "\n",
        "# ── Fix Import Shadowing ─────────────────────────────────────────────────────\n",
        "# The repo is at /content/learn2learn. The package is /content/learn2learn/learn2learn.\n",
        "# If CWD is /content, 'import learn2learn' finds the repo folder (namespace pkg) first.\n",
        "\n",
        "# 1. Force reload if already loaded incorrectly\n",
        "if \"learn2learn\" in sys.modules:\n",
        "    import learn2learn\n",
        "    # If it lacks __file__, it's likely the namespace package (broken)\n",
        "    if not hasattr(learn2learn, \"__file__\") or learn2learn.__file__ is None:\n",
        "        print(\"Creating fix: unloading broken learn2learn module...\")\n",
        "        del sys.modules[\"learn2learn\"]\n",
        "\n",
        "# 2. Prepend repo path to sys.path so the inner package is found first\n",
        "if os.path.exists(\"/content/learn2learn\"):\n",
        "    if \"/content/learn2learn\" not in sys.path:\n",
        "        sys.path.insert(0, \"/content/learn2learn\")\n",
        "\n",
        "import learn2learn as l2l\n",
        "print(f\"learn2learn imported from: {getattr(l2l, '__file__', 'unknown')}\")\n",
        "\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "# SWITCHED TO cifarFS for reliability (miniImageNet download is often unstable)\n",
        "ACTIVE_DATASET  = 'cifarFS'\n",
        "LOCAL_DATA_ROOT = pathlib.Path(\"/content/data\")\n",
        "LOCAL_DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ── Step 1: Download dataset via learn2learn ─────────────────────────────────\n",
        "from learn2learn.vision.datasets import (\n",
        "    MiniImagenet, TieredImagenet, CIFARFS, CUBirds200\n",
        ")\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "MEAN = [0.4712, 0.4499, 0.4031]\n",
        "STD  = [0.2726, 0.2634, 0.2794]\n",
        "\n",
        "BASE_TRANSFORM = transforms.Compose([\n",
        "    transforms.Resize(84),\n",
        "    transforms.CenterCrop(84),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(MEAN, STD),\n",
        "])\n",
        "AUG_TRANSFORM = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(84),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(0.4, 0.4, 0.4, 0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(MEAN, STD),\n",
        "])\n",
        "\n",
        "DATASET_CLS = {\n",
        "    'miniImageNet' : MiniImagenet,\n",
        "    'tieredImageNet': TieredImagenet,\n",
        "    'cifarFS'      : CIFARFS,\n",
        "    'cub'          : CUBirds200,\n",
        "}\n",
        "\n",
        "print(f\"Downloading / loading {ACTIVE_DATASET} …\")\n",
        "cls = DATASET_CLS[ACTIVE_DATASET]\n",
        "\n",
        "# download=True fetches the data automatically on first run.\n",
        "# Subsequent runs reuse the cached copy in LOCAL_DATA_ROOT.\n",
        "try:\n",
        "    train_dataset = cls(root=str(LOCAL_DATA_ROOT), mode='train',\n",
        "                        download=True, transform=BASE_TRANSFORM)\n",
        "    val_dataset   = cls(root=str(LOCAL_DATA_ROOT), mode='validation',\n",
        "                        download=True, transform=BASE_TRANSFORM)\n",
        "    test_dataset  = cls(root=str(LOCAL_DATA_ROOT), mode='test',\n",
        "                        download=True, transform=BASE_TRANSFORM)\n",
        "\n",
        "    # Wrap in MetaDataset to ensure labels_to_indices exists (needed for EpisodicSampler)\n",
        "    train_dataset = l2l.data.MetaDataset(train_dataset)\n",
        "    val_dataset   = l2l.data.MetaDataset(val_dataset)\n",
        "    test_dataset  = l2l.data.MetaDataset(test_dataset)\n",
        "\n",
        "    print(f\"{ACTIVE_DATASET} — \"\n",
        "          f\"train: {len(train_dataset.labels_to_indices)} classes, \"\n",
        "          f\"val: {len(val_dataset.labels_to_indices)} classes, \"\n",
        "          f\"test: {len(test_dataset.labels_to_indices)} classes\")\n",
        "    print(f\"Data stored at : {LOCAL_DATA_ROOT}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ Error downloading {ACTIVE_DATASET}: {e}\")\n",
        "    print(\"Tip: If miniImageNet fails, try switching ACTIVE_DATASET to 'cifarFS' or 'tieredImageNet'.\")\n",
        "    raise e\n",
        "\n",
        "# ── Step 2: Mount Google Drive for checkpoints / results ─────────────────────\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\", force_remount=False)\n",
        "    DRIVE_ROOT = pathlib.Path(\"/content/drive/MyDrive/FSAKE_Project\")\n",
        "except Exception:\n",
        "    # Running outside Colab (local dev) — use local fallback\n",
        "    DRIVE_ROOT = pathlib.Path(\"/tmp/FSAKE_Project\")\n",
        "    print(\"Not running on Colab — Drive fallback at:\", DRIVE_ROOT)\n",
        "\n",
        "CKPT_DIR    = DRIVE_ROOT / \"checkpoints\"\n",
        "RESULTS_DIR = DRIVE_ROOT / \"results\"\n",
        "CKPT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"CKPT dir    :\", CKPT_DIR)\n",
        "print(\"Results dir :\", RESULTS_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83432efc",
      "metadata": {
        "id": "83432efc"
      },
      "source": [
        "## Section 3: Dataset & Episodic Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c796e95f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "c796e95f",
        "outputId": "b953d09a-616e-4feb-d2af-f9bd17378041"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EpisodicSampler ready: 64 classes, 5-way 1-shot 15-query\n",
            "EpisodicSampler ready: 16 classes, 5-way 1-shot 15-query\n",
            "EpisodicSampler ready: 20 classes, 5-way 1-shot 15-query\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Dataset must expose .labels_to_indices or .y",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4207229107.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLOCAL_DATA_ROOT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     download=False, transform=AUG_TRANSFORM)\n\u001b[0;32m---> 94\u001b[0;31m \u001b[0mtrain_sampler_aug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEpisodicSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset_aug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_way\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_query\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;31m# ── Quick episode sanity check ────────────────────────────────────────────────\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4207229107.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, n_way, k_shot, n_query)\u001b[0m\n\u001b[1;32m     48\u001b[0m             }\n\u001b[1;32m     49\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dataset must expose .labels_to_indices or .y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_to_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Dataset must expose .labels_to_indices or .y"
          ]
        }
      ],
      "source": [
        "# ── Section 3: Dataset & Episodic Loader ─────────────────────────────────────\n",
        "# Wraps the learn2learn datasets (loaded in Section 2) into a simple episodic\n",
        "# sampler. Works with miniImageNet, tieredImageNet, CIFAR-FS, and CUB.\n",
        "#\n",
        "# Episodic protocol:\n",
        "#   S = N_way × K_shot  support samples  (labeled)\n",
        "#   Q = N_way × N_query query  samples  (unlabeled at inference)\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# ── Generic episodic sampler wrapping any learn2learn dataset ─────────────────\n",
        "\n",
        "class EpisodicSampler:\n",
        "    \"\"\"\n",
        "    Wraps a learn2learn dataset (which exposes `labels_to_indices` dict)\n",
        "    and samples N-way K-shot episodes on demand.\n",
        "\n",
        "    Usage:\n",
        "        sampler = EpisodicSampler(train_dataset, n_way=5, k_shot=1, n_query=15)\n",
        "        s_imgs, s_lbl, q_imgs, q_lbl = sampler.sample()   # one episode\n",
        "\n",
        "    Can also be called as a function (for compatibility with train/eval loops):\n",
        "        s_imgs, s_lbl, q_imgs, q_lbl = sampler(n_way=5, k_shot=1, n_query=15)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataset, n_way: int = 5, k_shot: int = 1,\n",
        "                 n_query: int = 15):\n",
        "        self.dataset  = dataset\n",
        "        self.n_way    = n_way\n",
        "        self.k_shot   = k_shot\n",
        "        self.n_query  = n_query\n",
        "\n",
        "        # Build class → list[global_index] map\n",
        "        if hasattr(dataset, 'labels_to_indices'):\n",
        "            self.class_to_indices = {\n",
        "                c: list(idxs)\n",
        "                for c, idxs in dataset.labels_to_indices.items()\n",
        "                if len(idxs) >= k_shot + n_query\n",
        "            }\n",
        "        elif hasattr(dataset, 'y'):\n",
        "            import numpy as _np\n",
        "            _labels = _np.array(dataset.y)\n",
        "            self.class_to_indices = {\n",
        "                int(c): list(_np.where(_labels == c)[0])\n",
        "                for c in _np.unique(_labels)\n",
        "                if len(_np.where(_labels == c)[0]) >= k_shot + n_query\n",
        "            }\n",
        "        else:\n",
        "            raise ValueError(\"Dataset must expose .labels_to_indices or .y\")\n",
        "\n",
        "        self.classes = sorted(self.class_to_indices.keys())\n",
        "        assert len(self.classes) >= n_way, (\n",
        "            f\"Only {len(self.classes)} classes available, N-way={n_way}\")\n",
        "        print(f\"EpisodicSampler ready: {len(self.classes)} classes, \"\n",
        "              f\"{n_way}-way {k_shot}-shot {n_query}-query\")\n",
        "\n",
        "    def sample(self):\n",
        "        \"\"\"Returns (support_imgs, support_labels, query_imgs, query_labels).\"\"\"\n",
        "        episode_classes = random.sample(self.classes, self.n_way)\n",
        "        s_imgs, s_labels, q_imgs, q_labels = [], [], [], []\n",
        "        for local_lbl, cls in enumerate(episode_classes):\n",
        "            pool = random.sample(self.class_to_indices[cls],\n",
        "                                 self.k_shot + self.n_query)\n",
        "            for i, idx in enumerate(pool):\n",
        "                img, _ = self.dataset[idx]       # transform applied by dataset\n",
        "                if not isinstance(img, torch.Tensor):\n",
        "                    from torchvision.transforms.functional import to_tensor\n",
        "                    img = to_tensor(img)\n",
        "                if i < self.k_shot:\n",
        "                    s_imgs.append(img);   s_labels.append(local_lbl)\n",
        "                else:\n",
        "                    q_imgs.append(img);   q_labels.append(local_lbl)\n",
        "        return (torch.stack(s_imgs),  torch.tensor(s_labels, dtype=torch.long),\n",
        "                torch.stack(q_imgs),  torch.tensor(q_labels, dtype=torch.long))\n",
        "\n",
        "    def __call__(self, n_way=None, k_shot=None, n_query=None):\n",
        "        \"\"\"Allow calling as episode_fn(n_way, k_shot, n_query) for loop compat.\"\"\"\n",
        "        if n_way   is not None: self.n_way   = n_way\n",
        "        if k_shot  is not None: self.k_shot  = k_shot\n",
        "        if n_query is not None: self.n_query = n_query\n",
        "        return self.sample()\n",
        "\n",
        "\n",
        "# ── Instantiate samplers for all three splits ─────────────────────────────────\n",
        "train_sampler = EpisodicSampler(train_dataset, n_way=5, k_shot=1, n_query=15)\n",
        "val_sampler   = EpisodicSampler(val_dataset,   n_way=5, k_shot=1, n_query=15)\n",
        "test_sampler  = EpisodicSampler(test_dataset,  n_way=5, k_shot=1, n_query=15)\n",
        "\n",
        "# Augmented training sampler (same data, richer color/crop augmentation)\n",
        "train_dataset_aug = DATASET_CLS[ACTIVE_DATASET](\n",
        "    root=str(LOCAL_DATA_ROOT), mode='train',\n",
        "    download=False, transform=AUG_TRANSFORM)\n",
        "train_sampler_aug = EpisodicSampler(train_dataset_aug, n_way=5, k_shot=1, n_query=15)\n",
        "\n",
        "# ── Quick episode sanity check ────────────────────────────────────────────────\n",
        "_s_imgs, _s_lbl, _q_imgs, _q_lbl = train_sampler.sample()\n",
        "print(f\"Support : {_s_imgs.shape}  labels={_s_lbl.tolist()}\")\n",
        "print(f\"Query   : {_q_imgs.shape}  labels={_q_lbl[:5].tolist()}…\")\n",
        "\n",
        "# ── Synthetic planted-partition episode generator (Section 2.3) ───────────────\n",
        "\n",
        "def synthetic_episode(n_way=5, n_nodes_per_class=5, feat_dim=64,\n",
        "                      sigma=0.8, device=DEVICE):\n",
        "    \"\"\"\n",
        "    Generate a planted-partition episode for topology-recovery experiments.\n",
        "    Returns node features X, labels y, and ground-truth adjacency A_star.\n",
        "    sigma controls noise: larger sigma → harder topology recovery.\n",
        "    \"\"\"\n",
        "    centers = torch.randn(n_way, feat_dim)\n",
        "    center_dists = [\n",
        "        (centers[i] - centers[j]).norm().item()\n",
        "        for i in range(n_way)\n",
        "        for j in range(i + 1, n_way)\n",
        "    ]\n",
        "    avg_sep = sum(center_dists) / len(center_dists)\n",
        "\n",
        "    N = n_way * n_nodes_per_class\n",
        "    X = torch.zeros(N, feat_dim)\n",
        "    y = torch.zeros(N, dtype=torch.long)\n",
        "    for c in range(n_way):\n",
        "        sl = slice(c * n_nodes_per_class, (c + 1) * n_nodes_per_class)\n",
        "        X[sl] = centers[c] + sigma * avg_sep * torch.randn(n_nodes_per_class, feat_dim)\n",
        "        y[sl] = c\n",
        "\n",
        "    # Ground-truth: intra-class = 1, inter-class = 0, no self-loops\n",
        "    A_star = (y.unsqueeze(0) == y.unsqueeze(1)).float()\n",
        "    A_star.fill_diagonal_(0)\n",
        "    return X.to(device), y.to(device), A_star.to(device)\n",
        "\n",
        "\n",
        "# ── Quick sanity check ────────────────────────────────────────────────────────\n",
        "X_syn, y_syn, A_syn = synthetic_episode(n_way=5, n_nodes_per_class=4, feat_dim=64, sigma=0.6)\n",
        "print(f\"Synthetic X:{X_syn.shape}  y:{y_syn.shape}  A*:{A_syn.shape}\")\n",
        "print(f\"Intra-class edges: {int(A_syn.sum().item())} \"\n",
        "      f\"(expected {5 * 4 * 3} for 5 classes, 4 nodes each)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be393c8a",
      "metadata": {
        "id": "be393c8a"
      },
      "source": [
        "## Section 4: Backbone Network (Conv4)\n",
        "Bit-for-bit identical to the FSAKE backbone. 128-dim output embedding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1852ac82",
      "metadata": {
        "id": "1852ac82"
      },
      "outputs": [],
      "source": [
        "# ── Section 4: Backbone Network (Conv4) ──────────────────────────────────────\n",
        "import torch.nn as nn\n",
        "\n",
        "def conv_block(in_ch: int, out_ch: int) -> nn.Sequential:\n",
        "    \"\"\"Standard FSAKE conv block: Conv → BN → ReLU → MaxPool.\"\"\"\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
        "        nn.BatchNorm2d(out_ch),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.MaxPool2d(kernel_size=2),\n",
        "    )\n",
        "\n",
        "\n",
        "class Conv4(nn.Module):\n",
        "    \"\"\"\n",
        "    4-layer convolutional backbone identical to FSAKE.\n",
        "    Input : (B, 3, 84, 84)\n",
        "    Output: (B, embed_dim) — default 128 to match FSAKE paper.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels: int = 3, embed_dim: int = 128):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            conv_block(in_channels, 64),   # → 42×42\n",
        "            conv_block(64, 64),            # → 21×21\n",
        "            conv_block(64, 64),            # → 10×10\n",
        "            conv_block(64, 64),            # →  5× 5\n",
        "        )\n",
        "        self.proj = nn.Linear(64 * 5 * 5, embed_dim)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        h = self.encoder(x)                          # (B, 64, 5, 5)\n",
        "        h = h.view(h.size(0), -1)                    # (B, 1600)\n",
        "        return self.proj(h)                          # (B, embed_dim)\n",
        "\n",
        "\n",
        "# ── Sanity check ─────────────────────────────────────────────────────────────\n",
        "_backbone = Conv4(embed_dim=128).to(DEVICE)\n",
        "_dummy    = torch.randn(10, 3, 84, 84).to(DEVICE)\n",
        "_out      = _backbone(_dummy)\n",
        "print(\"Conv4 output shape:\", _out.shape)   # expect (10, 128)\n",
        "assert _out.shape == (10, 128), \"Backbone shape mismatch!\"\n",
        "total_params = sum(p.numel() for p in _backbone.parameters() if p.requires_grad)\n",
        "print(f\"Conv4 trainable parameters: {total_params:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fec2b37c",
      "metadata": {
        "id": "fec2b37c"
      },
      "source": [
        "## Section 5: Static k-NN Graph Module (FSAKE Baseline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41e7e43c",
      "metadata": {
        "id": "41e7e43c"
      },
      "outputs": [],
      "source": [
        "# ── Section 5: Static k-NN Graph Module (FSAKE Baseline) ─────────────────────\n",
        "# Builds A ∈ R^{N×N} from pairwise Euclidean distances; retains top-k per node.\n",
        "# This is the graph construction used by FSAKE — plug-in swappable.\n",
        "\n",
        "def build_knn_adjacency(node_feats: torch.Tensor, k: int,\n",
        "                        symmetric: bool = True) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Args\n",
        "    ----\n",
        "    node_feats : (N, d) node embeddings\n",
        "    k          : number of nearest neighbours per node\n",
        "    symmetric  : if True, A = max(A, A^T) (undirected graph)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    A : (N, N) float adjacency (0/1 values, no self-loops, row-normalised)\n",
        "    \"\"\"\n",
        "    N = node_feats.size(0)\n",
        "    # Pairwise squared Euclidean distance\n",
        "    diff = node_feats.unsqueeze(0) - node_feats.unsqueeze(1)   # (N,N,d)\n",
        "    dist = (diff ** 2).sum(-1)                                  # (N,N)\n",
        "\n",
        "    # Mask self (set diagonal to large value so it is not selected in top-k)\n",
        "    dist_masked = dist.clone()\n",
        "    dist_masked.fill_diagonal_(float(\"inf\"))\n",
        "\n",
        "    # Keep k SMALLEST distances (nearest neighbours) → set all others to 0\n",
        "    _, topk_idx = dist_masked.topk(k, dim=1, largest=False)\n",
        "    A = torch.zeros(N, N, dtype=torch.float32, device=node_feats.device)\n",
        "    A.scatter_(1, topk_idx, 1.0)\n",
        "\n",
        "    if symmetric:\n",
        "        A = torch.max(A, A.t())\n",
        "\n",
        "    # Row-normalise (D^{-1} A)\n",
        "    deg = A.sum(dim=1, keepdim=True).clamp(min=1e-6)\n",
        "    A_norm = A / deg\n",
        "    return A_norm\n",
        "\n",
        "\n",
        "# ── Graph utility: density ────────────────────────────────────────────────────\n",
        "\n",
        "def graph_density(A: torch.Tensor) -> float:\n",
        "    \"\"\"Fraction of possible directed edges that are non-zero (excl. diagonal).\"\"\"\n",
        "    N = A.size(0)\n",
        "    possible = N * (N - 1)\n",
        "    actual   = (A > 0).float().sum().item() - (A.diagonal() > 0).float().sum().item()\n",
        "    density  = actual / possible if possible > 0 else 0.0\n",
        "    if density > 0.5:\n",
        "        print(f\"⚠  Graph density = {density:.3f} > 0.5 — risk of topology collapse!\")\n",
        "    return density\n",
        "\n",
        "\n",
        "# ── Sanity check ─────────────────────────────────────────────────────────────\n",
        "_feats = torch.randn(20, 128).to(DEVICE)\n",
        "_A_knn = build_knn_adjacency(_feats, k=5)\n",
        "d = graph_density(_A_knn)\n",
        "print(f\"k-NN adjacency shape: {_A_knn.shape}  density: {d:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef0f61f8",
      "metadata": {
        "id": "ef0f61f8"
      },
      "source": [
        "## Section 6: Edge Incidence Matrix & Dynamic Edge Features\n",
        "\n",
        "**Key distinction from attention**: Attention produces a *scalar* weight per edge. Computing $E = BXW$ via the incidence matrix $B \\in \\{0,1\\}^{N \\times |E|}$ produces a *vector* $e_{ij} \\in \\mathbb{R}^d$ per edge — a $d$-dimensional signal retaining directional and heterogeneous relational information. This is equivalent to one step of line-graph convolution, where edges are first-class computational objects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c526db16",
      "metadata": {
        "id": "c526db16"
      },
      "outputs": [],
      "source": [
        "# ── Section 6: Edge Incidence Matrix & Dynamic Edge Features ─────────────────\n",
        "# B ∈ {0,1}^{N × |E|}  maps each edge to its two incident nodes.\n",
        "# E = B^T X W  →  each edge gets a vector representation in R^d.\n",
        "\n",
        "class EdgeIncidenceModule(nn.Module):\n",
        "    \"\"\"\n",
        "    Builds the edge incidence matrix B from a given adjacency A,\n",
        "    then computes edge features E = B^T X W using a shallow MLP.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    in_dim  : node feature dimension d\n",
        "    edge_dim: output edge feature dimension (default = in_dim for skip-compat.)\n",
        "    hidden  : hidden dim of the 2-layer edge MLP (≤ 64 to avoid overfit)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_dim: int, edge_dim: int = None, hidden: int = 64):\n",
        "        super().__init__()\n",
        "        edge_dim = edge_dim or in_dim\n",
        "        self.edge_mlp = nn.Sequential(\n",
        "            nn.Linear(2 * in_dim, hidden, bias=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(hidden, edge_dim, bias=True),\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def adjacency_to_edge_index(A: torch.Tensor):\n",
        "        \"\"\"Return (src, dst) index arrays for all non-zero entries of A.\"\"\"\n",
        "        nz = A.nonzero(as_tuple=True)\n",
        "        return nz[0], nz[1]         # src, dst\n",
        "\n",
        "    def forward(self, X: torch.Tensor, A: torch.Tensor):\n",
        "        \"\"\"\n",
        "        X : (N, d)  node features\n",
        "        A : (N, N)  adjacency (may be weighted)\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        E         : (|E|, edge_dim)  vector edge features\n",
        "        src, dst  : edge index tensors\n",
        "        \"\"\"\n",
        "        src, dst = self.adjacency_to_edge_index(A)\n",
        "        # Concatenate incident node features for each edge\n",
        "        edge_input = torch.cat([X[src], X[dst]], dim=-1)    # (|E|, 2d)\n",
        "        E = self.edge_mlp(edge_input)                        # (|E|, edge_dim)\n",
        "        return E, src, dst\n",
        "\n",
        "\n",
        "# ── Sanity check ─────────────────────────────────────────────────────────────\n",
        "_eim   = EdgeIncidenceModule(in_dim=128, edge_dim=128, hidden=64).to(DEVICE)\n",
        "_feats = torch.randn(20, 128).to(DEVICE)\n",
        "_A     = build_knn_adjacency(_feats, k=5)\n",
        "_E, _src, _dst = _eim(_feats, _A)\n",
        "print(f\"Edge features shape : {_E.shape}   (|E|={len(_src)}, edge_dim=128)\")\n",
        "print(f\"src index range     : {_src.min().item()} – {_src.max().item()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32420d5e",
      "metadata": {
        "id": "32420d5e"
      },
      "source": [
        "## Section 7: Adaptive Topology Reconstruction\n",
        "\n",
        "Low-rank bilinear scoring: $s_{ij} = (W_1 h_i)^\\top (W_2 h_j)$ with rank $r \\ll d$ bounds overfitting. Spectral normalization bounds $L_f$ (Lipschitz). Row-normalisation of $A'$ bounds $L_{MP}$. Together they ensure contraction (Proposition 3)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "063b6223",
      "metadata": {
        "id": "063b6223"
      },
      "outputs": [],
      "source": [
        "# ── Section 7: Adaptive Topology Reconstruction ───────────────────────────────\n",
        "from torch.nn.utils.parametrizations import spectral_norm as spectral_norm_wrap\n",
        "\n",
        "class DynamicTopologyModule(nn.Module):\n",
        "    \"\"\"\n",
        "    Learns A'(l) = f(H(l)) using low-rank bilinear scoring.\n",
        "\n",
        "    s_ij = (W1 h_i)^T (W2 h_j) / sqrt(r)     [low-rank, rank r << d]\n",
        "\n",
        "    Spectral normalization on W1,W2 → Lipschitz bound on f.\n",
        "    Row-normalization of A'          → Lipschitz bound on MP.\n",
        "\n",
        "    sparsity_mode ∈ {'none', 'l1', 'topk', 'laplacian'}\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, feat_dim: int, rank: int = 16, edge_dim: int = 128,\n",
        "                 sparsity_mode: str = \"l1\", topk: int = 5,\n",
        "                 lambda_sparse: float = 0.01, edge_dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.rank          = rank\n",
        "        self.sparsity_mode = sparsity_mode\n",
        "        self.topk          = topk\n",
        "        self.lambda_sparse = lambda_sparse\n",
        "        self.edge_dropout  = edge_dropout\n",
        "\n",
        "        # Low-rank projection (spectral-normalised)\n",
        "        self.W1 = spectral_norm_wrap(nn.Linear(feat_dim, rank, bias=False))\n",
        "        self.W2 = spectral_norm_wrap(nn.Linear(feat_dim, rank, bias=False))\n",
        "\n",
        "        # Edge → A' scoring via edge feature dot-product\n",
        "        self.edge_scorer = spectral_norm_wrap(\n",
        "            nn.Linear(edge_dim, 1, bias=False))\n",
        "\n",
        "    def forward(self, H: torch.Tensor, E: torch.Tensor,\n",
        "                src: torch.Tensor, dst: torch.Tensor,\n",
        "                sparsity_reg: bool = True):\n",
        "        \"\"\"\n",
        "        H   : (N, d)      node features\n",
        "        E   : (|E|, d_e)  edge features from EdgeIncidenceModule\n",
        "        src,dst : edge indices\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        A_prime       : (N, N)  new normalised adjacency\n",
        "        sparsity_loss : scalar  (0 if sparsity_reg=False)\n",
        "        \"\"\"\n",
        "        N = H.size(0)\n",
        "\n",
        "        # ── Low-rank bilinear scores ─────────────────────────────────────────\n",
        "        scores_bilinear = (self.W1(H[src]) * self.W2(H[dst])).sum(-1) / (self.rank ** 0.5)\n",
        "\n",
        "        # ── Edge-feature scores ──────────────────────────────────────────────\n",
        "        scores_edge     = self.edge_scorer(E).squeeze(-1)\n",
        "\n",
        "        edge_scores = scores_bilinear + scores_edge\n",
        "\n",
        "        # ── Dropout on edge weights during training ──────────────────────────\n",
        "        if self.training and self.edge_dropout > 0:\n",
        "            mask = torch.bernoulli(\n",
        "                torch.full_like(edge_scores, 1 - self.edge_dropout))\n",
        "            edge_scores = edge_scores * mask\n",
        "\n",
        "        # ── Soft adjacency via sigmoid ────────────────────────────────────────\n",
        "        edge_weights = torch.sigmoid(edge_scores)\n",
        "\n",
        "        # ── Build dense A' ────────────────────────────────────────────────────\n",
        "        A_prime = torch.zeros(N, N, device=H.device, dtype=H.dtype)\n",
        "        A_prime[src, dst] = edge_weights\n",
        "\n",
        "        # ── Sparsity regularisation ───────────────────────────────────────────\n",
        "        sparsity_loss = torch.tensor(0.0, device=H.device)\n",
        "        if sparsity_reg:\n",
        "            if self.sparsity_mode == \"l1\":\n",
        "                sparsity_loss = self.lambda_sparse * A_prime.abs().mean()\n",
        "            elif self.sparsity_mode == \"topk\":\n",
        "                # Hard top-k mask (gradient stops here — ablation only)\n",
        "                vals, idx = A_prime.topk(self.topk, dim=1)\n",
        "                mask = torch.zeros_like(A_prime)\n",
        "                mask.scatter_(1, idx, 1.0)\n",
        "                A_prime = A_prime * mask.detach()\n",
        "            elif self.sparsity_mode == \"laplacian\":\n",
        "                # tr(H^T L H) where L = D - A'\n",
        "                D = A_prime.sum(dim=1).diag()\n",
        "                L = D - A_prime\n",
        "                sparsity_loss = self.lambda_sparse * torch.trace(H.t() @ L @ H)\n",
        "\n",
        "        # ── Row-normalise (Proposition 3 Lipschitz control) ──────────────────\n",
        "        deg = A_prime.sum(dim=1, keepdim=True).clamp(min=1e-6)\n",
        "        A_prime = A_prime / deg\n",
        "\n",
        "        return A_prime, sparsity_loss\n",
        "\n",
        "\n",
        "# ── Sanity check ─────────────────────────────────────────────────────────────\n",
        "_dtm   = DynamicTopologyModule(feat_dim=128, rank=16, edge_dim=128).to(DEVICE)\n",
        "_A_dyn, _sl = _dtm(_feats, _E, _src, _dst)\n",
        "print(f\"Dynamic A' shape: {_A_dyn.shape}  sparsity_loss={_sl.item():.4f}\")\n",
        "print(f\"Graph density   : {graph_density(_A_dyn):.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f8c09bd",
      "metadata": {
        "id": "6f8c09bd"
      },
      "source": [
        "## Section 8: Knowledge Filtering with Edge Awareness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a310f22",
      "metadata": {
        "id": "7a310f22"
      },
      "outputs": [],
      "source": [
        "# ── Section 8: Knowledge Filtering with Edge Awareness ───────────────────────\n",
        "# Node importance is now computed from aggregated *edge* representations\n",
        "# rather than raw 1-hop degree counts (as in vanilla FSAKE).\n",
        "# High-importance nodes gate the pooling step in the Graph U-Net path.\n",
        "\n",
        "class EdgeAwareKnowledgeFilter(nn.Module):\n",
        "    \"\"\"\n",
        "    Scores each node by aggregating its incident edge features, then\n",
        "    applies a learnable gating MLP to produce a scalar importance score.\n",
        "\n",
        "    importance_i = sigmoid( g( mean_{j: (i,j)∈E} e_{ij} ) )\n",
        "\n",
        "    The scores are used for top-p node selection (Graph U-Net pooling analog).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, edge_dim: int, node_dim: int, hidden: int = 64):\n",
        "        super().__init__()\n",
        "        self.gate = nn.Sequential(\n",
        "            nn.Linear(edge_dim + node_dim, hidden),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(hidden, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, H: torch.Tensor, E: torch.Tensor,\n",
        "                src: torch.Tensor, A_prime: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        H       : (N, d)\n",
        "        E       : (|E|, edge_dim)\n",
        "        src     : edge src indices\n",
        "        A_prime : (N, N) row-normalised dynamic adjacency\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        scores  : (N,) importance scores in [0,1]\n",
        "        H_pooled: (N, d) weighted node update  X' = A' E W'  via scatter\n",
        "        \"\"\"\n",
        "        N = H.size(0)\n",
        "        edge_dim = E.size(1)\n",
        "\n",
        "        # Aggregate edge features per source node: mean of incident edges\n",
        "        agg = torch.zeros(N, edge_dim, device=H.device)\n",
        "        agg.scatter_add_(0, src.unsqueeze(-1).expand_as(E), E)\n",
        "        counts = torch.zeros(N, device=H.device).scatter_add_(\n",
        "            0, src, torch.ones(len(src), device=H.device))\n",
        "        agg = agg / counts.unsqueeze(-1).clamp(min=1)\n",
        "\n",
        "        # Gate: importance score from (aggregated edge features ∥ node feat)\n",
        "        gate_input = torch.cat([agg, H], dim=-1)\n",
        "        scores     = torch.sigmoid(self.gate(gate_input)).squeeze(-1)   # (N,)\n",
        "\n",
        "        # Edge-to-node update: X' = A' · scatter(E) → message passing\n",
        "        H_pooled = A_prime @ H                              # (N, d) simple MP\n",
        "        H_pooled = H_pooled * scores.unsqueeze(-1)          # gate by importance\n",
        "\n",
        "        return scores, H_pooled\n",
        "\n",
        "\n",
        "# ── Sanity check ─────────────────────────────────────────────────────────────\n",
        "_kf = EdgeAwareKnowledgeFilter(edge_dim=128, node_dim=128).to(DEVICE)\n",
        "_scores, _H_pool = _kf(_feats, _E, _src, _A_dyn)\n",
        "print(f\"Node scores shape : {_scores.shape}\")\n",
        "print(f\"H_pooled shape    : {_H_pool.shape}\")\n",
        "print(f\"Score range       : [{_scores.min():.3f}, {_scores.max():.3f}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22a54eb1",
      "metadata": {
        "id": "22a54eb1"
      },
      "source": [
        "## Section 9: Supervised Edge Loss (Support-Support Only)\n",
        "\n",
        "**Label-leakage prevention (Risk 5)**: The correction loss is computed **only on support-support pairs**. Query nodes never appear as supervision targets — they receive topology updates passively via message passing from the learned support graph.\n",
        "\n",
        "$$\\mathcal{L}_{edge} = \\sum_{i,j \\in \\mathcal{S}} \\mathbb{1}[y_i = y_j](1 - \\cos(e_{ij})) + \\mathbb{1}[y_i \\neq y_j]\\max(0, \\cos(e_{ij}) - m)$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e11a7cad",
      "metadata": {
        "id": "e11a7cad"
      },
      "outputs": [],
      "source": [
        "# ── Section 9: Supervised Edge Loss (Support-Support Only) ───────────────────\n",
        "\n",
        "def edge_correction_loss(E: torch.Tensor,\n",
        "                         src: torch.Tensor,\n",
        "                         dst: torch.Tensor,\n",
        "                         labels: torch.Tensor,\n",
        "                         support_mask: torch.Tensor,\n",
        "                         margin: float = 0.5) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Computes the edge-level contrastive correction loss.\n",
        "\n",
        "    IMPORTANT: only support→support edges are used.\n",
        "    An assertion guarantees no query indices leak into this computation.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    E            : (|E|, d)  edge features from EdgeIncidenceModule\n",
        "    src, dst     : edge endpoint indices (for ALL edges in the graph)\n",
        "    labels       : (N,) — labels for support nodes; query labels NOT used\n",
        "    support_mask : (N,) bool — True if node i is in the support set\n",
        "    margin       : contrastive margin m\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    loss : scalar\n",
        "    \"\"\"\n",
        "    # ── Strict label-leakage guard ────────────────────────────────────────────\n",
        "    support_indices = support_mask.nonzero(as_tuple=True)[0]\n",
        "    support_set     = set(support_indices.cpu().tolist())\n",
        "\n",
        "    # Keep only support-support edges\n",
        "    ss_mask = support_mask[src] & support_mask[dst]\n",
        "\n",
        "    # ASSERT: no query node sneaks into the loss\n",
        "    assert ss_mask.sum().item() <= (support_mask.sum() ** 2).item(), \\\n",
        "        \"Edge loss applied to non-support edges — label leakage!\"\n",
        "\n",
        "    if ss_mask.sum().item() == 0:\n",
        "        return torch.tensor(0.0, device=E.device, requires_grad=True)\n",
        "\n",
        "    E_ss   = E[ss_mask]\n",
        "    src_ss = src[ss_mask]\n",
        "    dst_ss = dst[ss_mask]\n",
        "\n",
        "    # Cosine similarity between edge endpoint features (proxy: edge features)\n",
        "    cos_sim = F.cosine_similarity(E_ss[:, :E_ss.size(1)//2],\n",
        "                                  E_ss[:, E_ss.size(1)//2:], dim=-1)\n",
        "    # For the actual implementation use the edge vectors directly:\n",
        "    # cos_sim = F.cosine_similarity(E_ss, ...) — simplified here\n",
        "\n",
        "    same_class = (labels[src_ss] == labels[dst_ss]).float()\n",
        "\n",
        "    pull_loss = same_class       * (1 - cos_sim)\n",
        "    push_loss = (1 - same_class) * torch.clamp(cos_sim - margin, min=0)\n",
        "\n",
        "    return (pull_loss + push_loss).mean()\n",
        "\n",
        "\n",
        "# ── Sanity check ─────────────────────────────────────────────────────────────\n",
        "# Simulate 5-way 1-shot (5 support) + 15 query nodes\n",
        "_N_total   = 20\n",
        "_n_support = 5\n",
        "_labels_s  = torch.arange(_n_support).to(DEVICE)              # support labels\n",
        "_labels    = torch.cat([_labels_s,\n",
        "                        torch.zeros(_N_total - _n_support, dtype=torch.long).to(DEVICE)])\n",
        "_sup_mask  = torch.zeros(_N_total, dtype=torch.bool).to(DEVICE)\n",
        "_sup_mask[:_n_support] = True\n",
        "\n",
        "_loss_edge = edge_correction_loss(_E, _src, _dst, _labels, _sup_mask)\n",
        "print(f\"Edge correction loss (support-only): {_loss_edge.item():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01e47238",
      "metadata": {
        "id": "01e47238"
      },
      "source": [
        "## Section 10: Sparsity Regularization\n",
        "\n",
        "Three togglable options — L1 (default, preserves variable degree), Laplacian smoothness, and top-k hard mask (ablation only). `graph_density()` raises a warning above 0.5 to detect collapse."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97068b00",
      "metadata": {
        "id": "97068b00"
      },
      "outputs": [],
      "source": [
        "# ── Section 10: Sparsity Regularization ──────────────────────────────────────\n",
        "# Standalone helpers (also used inside DynamicTopologyModule).\n",
        "\n",
        "def l1_sparsity_loss(A: torch.Tensor, lambda_: float = 0.01) -> torch.Tensor:\n",
        "    \"\"\"L1 regularisation on adjacency. Promotes sparse connectivity.\"\"\"\n",
        "    return lambda_ * A.abs().mean()\n",
        "\n",
        "\n",
        "def laplacian_smoothness_loss(A: torch.Tensor, H: torch.Tensor,\n",
        "                               lambda_: float = 0.01) -> torch.Tensor:\n",
        "    \"\"\"Laplacian smoothness: tr(H^T L H). Encourages connected nodes to agree.\"\"\"\n",
        "    D = A.sum(dim=1).diag()\n",
        "    L = D - A\n",
        "    return lambda_ * torch.trace(H.t() @ L @ H)\n",
        "\n",
        "\n",
        "def topk_mask(A: torch.Tensor, k: int) -> torch.Tensor:\n",
        "    \"\"\"Hard top-k per row (ablation variant E3 ONLY — enforces fixed degree).\"\"\"\n",
        "    # NOTE: gradient does not flow through this mask.\n",
        "    _, idx = A.topk(k, dim=1)\n",
        "    mask = torch.zeros_like(A)\n",
        "    mask.scatter_(1, idx, 1.0)\n",
        "    return A * mask.detach()\n",
        "\n",
        "\n",
        "def graph_metrics(A: torch.Tensor) -> dict:\n",
        "    \"\"\"\n",
        "    Returns a metrics dict for a single graph:\n",
        "      graph_density, avg_degree, degree_std, edge_entropy.\n",
        "    Raises a warning if density > 0.5.\n",
        "    \"\"\"\n",
        "    N   = A.size(0)\n",
        "    # Remove diagonal for degree counting\n",
        "    A_no_diag = A.clone()\n",
        "    A_no_diag.fill_diagonal_(0)\n",
        "\n",
        "    degree    = (A_no_diag > 0).float().sum(dim=1)      # (N,)\n",
        "    n_edges   = (A_no_diag > 0).float().sum().item()\n",
        "    density   = n_edges / max(N * (N - 1), 1)\n",
        "\n",
        "    # Edge entropy: treat each edge weight as a probability\n",
        "    weights   = A_no_diag[A_no_diag > 0]\n",
        "    p         = weights / weights.sum().clamp(min=1e-9)\n",
        "    edge_ent  = -(p * (p + 1e-9).log()).sum().item()\n",
        "\n",
        "    if density > 0.5:\n",
        "        print(f\"⚠  graph_density={density:.3f} > 0.5 — potential collapse\")\n",
        "\n",
        "    return {\n",
        "        \"graph_density\": density,\n",
        "        \"avg_degree\"   : degree.mean().item(),\n",
        "        \"degree_std\"   : degree.std().item(),\n",
        "        \"edge_entropy\" : edge_ent,\n",
        "    }\n",
        "\n",
        "\n",
        "# ── Demo ──────────────────────────────────────────────────────────────────────\n",
        "_metrics = graph_metrics(_A_dyn)\n",
        "print(\"Graph metrics:\", {k: round(v, 4) for k, v in _metrics.items()})\n",
        "print(\"L1 loss      :\", l1_sparsity_loss(_A_dyn).item())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86248de4",
      "metadata": {
        "id": "86248de4"
      },
      "source": [
        "## Section 11: Full Model Assembly (DEKAE)\n",
        "\n",
        "Forward pass: `node features + B → edge features E → dynamic A' → node update X' → knowledge filtering → skip connections`.\n",
        "\n",
        "Warm-up schedule: static k-NN topology for first `T_warm` epochs. Curriculum `λ_edge`: linearly ramps from 0 to `lambda_edge` over first 20 % of training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9806c81",
      "metadata": {
        "id": "b9806c81"
      },
      "outputs": [],
      "source": [
        "# ── Section 11: Full Model Assembly (DEKAE) ───────────────────────────────────\n",
        "\n",
        "class DEKAEModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Dynamic Edge-driven topology for Episodic few-shot learning (DEKAE).\n",
        "\n",
        "    Architecture per GNN layer\n",
        "    --------------------------\n",
        "    1. EdgeIncidenceModule   : X, A(l) → E(l), src, dst\n",
        "    2. DynamicTopologyModule : H(l), E(l) → A'(l), sparsity_loss\n",
        "    3. EdgeAwareKnowledgeFilter : H(l), E(l), A'(l) → scores, H(l+1)\n",
        "    4. Skip connection       : H(l+1) ← H(l+1) + H(0)\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    embed_dim     : backbone output dimension\n",
        "    n_gnn_layers  : number of dynamic GNN layers (default 3)\n",
        "    rank          : rank for low-rank bilinear scorer\n",
        "    sparsity_mode : 'l1' | 'topk' | 'laplacian' | 'none'\n",
        "    use_dynamic   : if False, fall back to static k-NN (FSAKE mode)\n",
        "    knn_k         : k for static k-NN fallback\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embed_dim: int = 128, n_gnn_layers: int = 3,\n",
        "                 rank: int = 16, sparsity_mode: str = \"l1\",\n",
        "                 lambda_sparse: float = 0.01, lambda_edge: float = 0.5,\n",
        "                 topk_k: int = 5, n_way: int = 5, use_dynamic: bool = True,\n",
        "                 edge_dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.embed_dim     = embed_dim\n",
        "        self.n_gnn_layers  = n_gnn_layers\n",
        "        self.n_way         = n_way\n",
        "        self.use_dynamic   = use_dynamic\n",
        "        self.knn_k         = topk_k\n",
        "        self.lambda_edge   = lambda_edge\n",
        "\n",
        "        self.backbone = Conv4(embed_dim=embed_dim)\n",
        "\n",
        "        self.edge_modules   = nn.ModuleList([\n",
        "            EdgeIncidenceModule(embed_dim, embed_dim, hidden=64)\n",
        "            for _ in range(n_gnn_layers)\n",
        "        ])\n",
        "        self.dynamic_modules = nn.ModuleList([\n",
        "            DynamicTopologyModule(embed_dim, rank, embed_dim,\n",
        "                                  sparsity_mode, topk_k, lambda_sparse,\n",
        "                                  edge_dropout)\n",
        "            for _ in range(n_gnn_layers)\n",
        "        ])\n",
        "        self.kf_modules = nn.ModuleList([\n",
        "            EdgeAwareKnowledgeFilter(embed_dim, embed_dim)\n",
        "            for _ in range(n_gnn_layers)\n",
        "        ])\n",
        "\n",
        "        self.classifier = nn.Linear(embed_dim, n_way)\n",
        "\n",
        "    # ── Warm-up helpers ───────────────────────────────────────────────────────\n",
        "    def set_use_dynamic(self, flag: bool):\n",
        "        self.use_dynamic = flag\n",
        "\n",
        "    # ── Forward ───────────────────────────────────────────────────────────────\n",
        "    def forward(self, imgs_support: torch.Tensor, labels_support: torch.Tensor,\n",
        "                imgs_query: torch.Tensor, lambda_edge_scale: float = 1.0):\n",
        "        \"\"\"\n",
        "        imgs_support : (N_s, 3, 84, 84)\n",
        "        labels_support : (N_s,)\n",
        "        imgs_query   : (N_q, 3, 84, 84)\n",
        "        lambda_edge_scale : curriculum multiplier [0,1] for edge loss\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        logits   : (N_q, n_way)\n",
        "        aux_loss : edge correction loss + sparsity losses\n",
        "        metrics  : dict with graph quality statistics\n",
        "        \"\"\"\n",
        "        N_s = imgs_support.size(0)\n",
        "        N_q = imgs_query.size(0)\n",
        "\n",
        "        # ── 1. Encode all nodes ───────────────────────────────────────────────\n",
        "        all_imgs  = torch.cat([imgs_support, imgs_query], dim=0)   # (N_s+N_q, ...)\n",
        "        H0        = self.backbone(all_imgs)                         # (N, d)\n",
        "\n",
        "        # Support mask (for edge loss — query nodes excluded)\n",
        "        support_mask = torch.zeros(N_s + N_q, dtype=torch.bool,\n",
        "                                   device=H0.device)\n",
        "        support_mask[:N_s] = True\n",
        "\n",
        "        H = H0\n",
        "        total_sparsity_loss = torch.tensor(0.0, device=H0.device)\n",
        "        total_edge_loss     = torch.tensor(0.0, device=H0.device)\n",
        "        layer_stability     = []           # ||H(l+1) - H(l)||_F for Prop. 3\n",
        "\n",
        "        for l in range(self.n_gnn_layers):\n",
        "            # ── 2. Build initial adjacency (warm-up: static; else: expand) ───\n",
        "            A_init = build_knn_adjacency(H, k=self.knn_k)\n",
        "\n",
        "            # ── 3. Edge features ──────────────────────────────────────────────\n",
        "            E, src, dst = self.edge_modules[l](H, A_init)\n",
        "\n",
        "            if self.use_dynamic:\n",
        "                # ── 4. Dynamic topology ───────────────────────────────────────\n",
        "                A_prime, sp_loss = self.dynamic_modules[l](H, E, src, dst)\n",
        "                total_sparsity_loss = total_sparsity_loss + sp_loss\n",
        "\n",
        "                # ── 5. Edge correction loss (support-support only) ─────────────\n",
        "                labels_full = torch.full((N_s + N_q,), -1, dtype=torch.long,\n",
        "                                         device=H.device)\n",
        "                labels_full[:N_s] = labels_support\n",
        "                e_loss_l = edge_correction_loss(E, src, dst, labels_full,\n",
        "                                                support_mask)\n",
        "                total_edge_loss = total_edge_loss + e_loss_l * lambda_edge_scale\n",
        "            else:\n",
        "                A_prime = A_init         # static fallback (warm-up / FSAKE mode)\n",
        "\n",
        "            # ── 6. Knowledge filtering & node update ──────────────────────────\n",
        "            _, H_new = self.kf_modules[l](H, E, src, A_prime)\n",
        "            H_new    = H_new + H0                                # skip connection\n",
        "\n",
        "            # Layer representation stability diagnostic (Proposition 3)\n",
        "            with torch.no_grad():\n",
        "                stability = (H_new - H).norm().item()\n",
        "            layer_stability.append(stability)\n",
        "\n",
        "            H = H_new\n",
        "\n",
        "        # ── 7. Classify query nodes via prototype cosine similarity ───────────\n",
        "        H_support = H[:N_s]                                   # (N_s, d)\n",
        "        H_query   = H[N_s:]                                   # (N_q, d)\n",
        "\n",
        "        # Compute class prototypes\n",
        "        prototypes = torch.zeros(self.n_way, self.embed_dim, device=H.device)\n",
        "        for c in range(self.n_way):\n",
        "            mask_c      = labels_support == c\n",
        "            prototypes[c] = H_support[mask_c].mean(0)\n",
        "\n",
        "        # Cosine similarity logits\n",
        "        H_q_norm   = F.normalize(H_query, dim=-1)\n",
        "        proto_norm = F.normalize(prototypes, dim=-1)\n",
        "        logits     = H_q_norm @ proto_norm.t()                 # (N_q, n_way)\n",
        "\n",
        "        aux_loss = (total_edge_loss * self.lambda_edge\n",
        "                    + total_sparsity_loss)\n",
        "\n",
        "        metrics = graph_metrics(A_prime)\n",
        "        metrics[\"layer_stability\"] = layer_stability\n",
        "\n",
        "        return logits, aux_loss, metrics\n",
        "\n",
        "\n",
        "# ── Sanity check ─────────────────────────────────────────────────────────────\n",
        "_model = DEKAEModel(n_way=5, embed_dim=128).to(DEVICE)\n",
        "_s_imgs = torch.randn(5, 3, 84, 84).to(DEVICE)       # 5-way 1-shot support\n",
        "_s_lbl  = torch.arange(5).to(DEVICE)\n",
        "_q_imgs = torch.randn(15, 3, 84, 84).to(DEVICE)      # 15 query imgs\n",
        "_logits, _aloss, _mets = _model(_s_imgs, _s_lbl, _q_imgs)\n",
        "print(f\"Logits shape : {_logits.shape}\")              # (15, 5)\n",
        "print(f\"Aux loss     : {_aloss.item():.4f}\")\n",
        "print(f\"Density      : {_mets['graph_density']:.3f}\")\n",
        "n_param = sum(p.numel() for p in _model.parameters())\n",
        "print(f\"Total params : {n_param:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e361d3d",
      "metadata": {
        "id": "0e361d3d"
      },
      "source": [
        "## Section 12: Training Loop with Checkpointing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88ed9b71",
      "metadata": {
        "id": "88ed9b71"
      },
      "outputs": [],
      "source": [
        "# ── Section 12: Training Loop with Checkpointing ─────────────────────────────\n",
        "import time, json\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# ── Hyperparameters (edit via config dict for ablations) ─────────────────────\n",
        "CFG = {\n",
        "    \"n_way\"          : 5,\n",
        "    \"k_shot\"         : 1,\n",
        "    \"n_query\"        : 15,\n",
        "    \"embed_dim\"      : 128,\n",
        "    \"n_gnn_layers\"   : 3,\n",
        "    \"rank\"           : 16,\n",
        "    \"sparsity_mode\"  : \"l1\",    # 'l1' | 'topk' | 'laplacian' | 'none'\n",
        "    \"lambda_sparse\"  : 0.01,\n",
        "    \"lambda_edge\"    : 0.5,\n",
        "    \"topk_k\"         : 5,\n",
        "    \"lr\"             : 5e-4,\n",
        "    \"weight_decay\"   : 1e-5,\n",
        "    \"n_episodes_train\": 300,     # episodes per epoch\n",
        "    \"n_epochs\"       : 100,\n",
        "    \"t_warm\"         : 5,        # warm-up epochs with static k-NN\n",
        "    \"edge_loss_ramp\" : 20,       # epochs over which lambda_edge ramps to final\n",
        "    \"grad_clip\"      : 1.0,\n",
        "    \"eval_every\"     : 5,        # validate every N epochs\n",
        "    \"n_eval_episodes\": 200,\n",
        "    \"seed\"           : 42,\n",
        "}\n",
        "\n",
        "\n",
        "def build_model(cfg: dict) -> DEKAEModel:\n",
        "    return DEKAEModel(\n",
        "        embed_dim    = cfg[\"embed_dim\"],\n",
        "        n_gnn_layers = cfg[\"n_gnn_layers\"],\n",
        "        rank         = cfg[\"rank\"],\n",
        "        sparsity_mode= cfg[\"sparsity_mode\"],\n",
        "        lambda_sparse= cfg[\"lambda_sparse\"],\n",
        "        lambda_edge  = cfg[\"lambda_edge\"],\n",
        "        topk_k       = cfg[\"topk_k\"],\n",
        "        n_way        = cfg[\"n_way\"],\n",
        "    ).to(DEVICE)\n",
        "\n",
        "\n",
        "def run_episode(model: DEKAEModel, episode_fn, n_way, k_shot, n_query,\n",
        "                lambda_edge_scale: float = 1.0):\n",
        "    \"\"\"\n",
        "    Runs one episode through the model and returns\n",
        "    (loss, accuracy, metrics_dict).\n",
        "    \"\"\"\n",
        "    s_imgs, s_lbl, q_imgs, q_lbl = episode_fn(n_way, k_shot, n_query)\n",
        "    s_imgs = s_imgs.to(DEVICE)\n",
        "    s_lbl  = s_lbl.to(DEVICE)\n",
        "    q_imgs = q_imgs.to(DEVICE)\n",
        "    q_lbl  = q_lbl.to(DEVICE)\n",
        "\n",
        "    logits, aux_loss, metrics = model(s_imgs, s_lbl, q_imgs, lambda_edge_scale)\n",
        "\n",
        "    cls_loss = F.cross_entropy(logits, q_lbl)\n",
        "    total    = cls_loss + aux_loss\n",
        "\n",
        "    preds   = logits.argmax(dim=1)\n",
        "    acc     = (preds == q_lbl).float().mean().item()\n",
        "    return total, acc, metrics\n",
        "\n",
        "\n",
        "def train(cfg: dict, episode_fn_train, episode_fn_val,\n",
        "          run_name: str = \"dekae\", log_wandb: bool = False):\n",
        "    \"\"\"\n",
        "    Full episodic training loop.\n",
        "\n",
        "    episode_fn_train / episode_fn_val : callables (n_way, k_shot, n_query)\n",
        "        returning (support_imgs, support_labels, query_imgs, query_labels)\n",
        "    \"\"\"\n",
        "    set_seed(cfg[\"seed\"])\n",
        "    model     = build_model(cfg)\n",
        "    optimizer = Adam(model.parameters(), lr=cfg[\"lr\"],\n",
        "                     weight_decay=cfg[\"weight_decay\"])\n",
        "    scheduler = StepLR(optimizer, step_size=20, gamma=0.5)\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "    history      = []\n",
        "\n",
        "    for epoch in range(1, cfg[\"n_epochs\"] + 1):\n",
        "        t_start = time.time()\n",
        "\n",
        "        # ── Warm-up: disable dynamic topology for first T_warm epochs ────────\n",
        "        model.set_use_dynamic(epoch > cfg[\"t_warm\"])\n",
        "\n",
        "        # ── Curriculum lambda_edge scaling ────────────────────────────────────\n",
        "        ramp_epochs      = cfg[\"edge_loss_ramp\"]\n",
        "        lambda_edge_scale = min(1.0, (epoch - cfg[\"t_warm\"]) / max(ramp_epochs, 1))\n",
        "        lambda_edge_scale = max(0.0, lambda_edge_scale)\n",
        "\n",
        "        # ── Training episodes ─────────────────────────────────────────────────\n",
        "        model.train()\n",
        "        train_losses, train_accs = [], []\n",
        "        grad_norms               = []\n",
        "\n",
        "        pbar = tqdm(range(cfg[\"n_episodes_train\"]),\n",
        "                    desc=f\"Ep {epoch}/{cfg['n_epochs']}\", leave=False)\n",
        "        for _ in pbar:\n",
        "            optimizer.zero_grad()\n",
        "            loss, acc, mets = run_episode(\n",
        "                model, episode_fn_train,\n",
        "                cfg[\"n_way\"], cfg[\"k_shot\"], cfg[\"n_query\"],\n",
        "                lambda_edge_scale\n",
        "            )\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient clipping (Risk 7 mitigation)\n",
        "            gnorm = nn.utils.clip_grad_norm_(model.parameters(), cfg[\"grad_clip\"])\n",
        "            grad_norms.append(gnorm)\n",
        "            optimizer.step()\n",
        "            train_losses.append(loss.item())\n",
        "            train_accs.append(acc)\n",
        "            pbar.set_postfix(loss=f\"{loss.item():.3f}\", acc=f\"{acc:.3f}\",\n",
        "                             density=f\"{mets['graph_density']:.2f}\")\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        # ── Validation ────────────────────────────────────────────────────────\n",
        "        val_acc_mean = 0.0\n",
        "        if epoch % cfg[\"eval_every\"] == 0:\n",
        "            model.eval()\n",
        "            val_accs = []\n",
        "            with torch.no_grad():\n",
        "                for _ in range(cfg[\"n_eval_episodes\"]):\n",
        "                    _, acc, _ = run_episode(\n",
        "                        model, episode_fn_val,\n",
        "                        cfg[\"n_way\"], cfg[\"k_shot\"], cfg[\"n_query\"])\n",
        "                    val_accs.append(acc)\n",
        "            val_acc_mean = float(np.mean(val_accs))\n",
        "            val_ci       = 1.96 * float(np.std(val_accs)) / (len(val_accs) ** 0.5)\n",
        "\n",
        "            # ── Checkpoint best model → Drive ─────────────────────────────────\n",
        "            if val_acc_mean > best_val_acc:\n",
        "                best_val_acc = val_acc_mean\n",
        "                ckpt_path    = CKPT_DIR / f\"{run_name}_best.pth\"\n",
        "                torch.save({\n",
        "                    \"epoch\"   : epoch,\n",
        "                    \"state\"   : model.state_dict(),\n",
        "                    \"val_acc\" : best_val_acc,\n",
        "                    \"cfg\"     : cfg,\n",
        "                }, str(ckpt_path))\n",
        "                print(f\"  ✓ New best val acc = {best_val_acc:.4f}  (ckpt saved)\")\n",
        "\n",
        "        epoch_time = time.time() - t_start\n",
        "        log = {\n",
        "            \"epoch\"           : epoch,\n",
        "            \"train_loss\"      : float(np.mean(train_losses)),\n",
        "            \"train_acc\"       : float(np.mean(train_accs)),\n",
        "            \"val_acc\"         : val_acc_mean,\n",
        "            \"grad_norm_mean\"  : float(np.mean(grad_norms)),\n",
        "            \"lambda_edge_scale\": lambda_edge_scale,\n",
        "            \"use_dynamic\"     : model.use_dynamic,\n",
        "            \"graph_density\"   : mets.get(\"graph_density\", 0),\n",
        "            \"avg_degree\"      : mets.get(\"avg_degree\", 0),\n",
        "            \"edge_entropy\"    : mets.get(\"edge_entropy\", 0),\n",
        "            \"layer_stability\" : mets.get(\"layer_stability\", []),\n",
        "            \"epoch_time_s\"    : epoch_time,\n",
        "        }\n",
        "        history.append(log)\n",
        "\n",
        "        # JSON backup to Drive every epoch\n",
        "        with open(str(RESULTS_DIR / f\"{run_name}_history.json\"), \"w\") as f:\n",
        "            json.dump(history, f)\n",
        "\n",
        "        if log_wandb:\n",
        "            import wandb\n",
        "            wandb.log(log)\n",
        "\n",
        "        if epoch % cfg[\"eval_every\"] == 0:\n",
        "            print(f\"Epoch {epoch:4d} | train_acc={log['train_acc']:.4f} \"\n",
        "                  f\"val_acc={val_acc_mean:.4f}±{val_ci:.4f} \"\n",
        "                  f\"density={log['graph_density']:.3f} \"\n",
        "                  f\"t={epoch_time:.1f}s\")\n",
        "\n",
        "    print(f\"\\nTraining complete. Best val acc: {best_val_acc:.4f}\")\n",
        "    return model, history\n",
        "\n",
        "\n",
        "print(\"Training loop defined. Call train(CFG, ...) to start.\")\n",
        "print(\"Model parameter count:\", sum(p.numel() for p in build_model(CFG).parameters()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "433302a8",
      "metadata": {
        "id": "433302a8"
      },
      "source": [
        "## Section 13: Evaluation & Statistical Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "444b4113",
      "metadata": {
        "id": "444b4113"
      },
      "outputs": [],
      "source": [
        "# ── Section 13: Evaluation & Statistical Testing ─────────────────────────────\n",
        "from scipy import stats as scipy_stats\n",
        "\n",
        "def evaluate(model: DEKAEModel, episode_fn, n_way: int, k_shot: int,\n",
        "             n_query: int, n_episodes: int = 1000) -> dict:\n",
        "    \"\"\"\n",
        "    Evaluate over n_episodes test episodes.\n",
        "    Returns accuracy mean, 95% CI, and full per-episode result dict.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    accs, densities, avg_degrees = [], [], []\n",
        "    intra_ratios, inter_ratios   = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in tqdm(range(n_episodes), desc=\"Evaluating\"):\n",
        "            s_imgs, s_lbl, q_imgs, q_lbl = episode_fn(n_way, k_shot, n_query)\n",
        "            s_imgs = s_imgs.to(DEVICE)\n",
        "            s_lbl  = s_lbl.to(DEVICE)\n",
        "            q_imgs = q_imgs.to(DEVICE)\n",
        "            q_lbl  = q_lbl.to(DEVICE)\n",
        "\n",
        "            logits, _, mets = model(s_imgs, s_lbl, q_imgs)\n",
        "            preds = logits.argmax(dim=1)\n",
        "            acc   = (preds == q_lbl).float().mean().item()\n",
        "            accs.append(acc)\n",
        "            densities.append(mets[\"graph_density\"])\n",
        "            avg_degrees.append(mets[\"avg_degree\"])\n",
        "\n",
        "    accs_np  = np.array(accs)\n",
        "    mean_acc = accs_np.mean()\n",
        "    ci_95    = 1.96 * accs_np.std() / (len(accs_np) ** 0.5)\n",
        "\n",
        "    return {\n",
        "        \"mean_acc\"    : mean_acc,\n",
        "        \"ci_95\"       : ci_95,\n",
        "        \"per_episode\" : accs,\n",
        "        \"avg_density\" : np.mean(densities),\n",
        "        \"avg_degree\"  : np.mean(avg_degrees),\n",
        "    }\n",
        "\n",
        "\n",
        "def paired_ttest(accs_a: list, accs_b: list) -> dict:\n",
        "    \"\"\"\n",
        "    Paired t-test between two models across the same episodes.\n",
        "    Returns t-statistic and p-value. p < 0.05 → significant improvement.\n",
        "    \"\"\"\n",
        "    t_stat, p_val = scipy_stats.ttest_rel(accs_b, accs_a)\n",
        "    return {\"t_statistic\": t_stat, \"p_value\": p_val,\n",
        "            \"significant_at_0.05\": p_val < 0.05}\n",
        "\n",
        "\n",
        "def compute_intra_inter_edge_ratio(A: torch.Tensor, labels: torch.Tensor):\n",
        "    \"\"\"\n",
        "    Given an adjacency matrix and node labels, compute the ratio of\n",
        "    intra-class and inter-class edges (for graph quality reporting).\n",
        "    \"\"\"\n",
        "    N = A.size(0)\n",
        "    intra = inter = 0\n",
        "    for i in range(N):\n",
        "        for j in range(N):\n",
        "            if i != j and A[i, j] > 0:\n",
        "                if labels[i] == labels[j]:\n",
        "                    intra += 1\n",
        "                else:\n",
        "                    inter += 1\n",
        "    total = intra + inter\n",
        "    return intra / max(total, 1), inter / max(total, 1)\n",
        "\n",
        "\n",
        "# ── Example usage (illustrative — replace dummy episode_fn with real loader) ──\n",
        "def _dummy_episode_fn(n_way, k_shot, n_query):\n",
        "    \"\"\"Placeholder using synthetic data — replace with real dataset loader.\"\"\"\n",
        "    s_imgs  = torch.randn(n_way * k_shot,  3, 84, 84)\n",
        "    s_lbl   = torch.repeat_interleave(torch.arange(n_way), k_shot)\n",
        "    q_imgs  = torch.randn(n_way * n_query, 3, 84, 84)\n",
        "    q_lbl   = torch.repeat_interleave(torch.arange(n_way), n_query)\n",
        "    return s_imgs, s_lbl, q_imgs, q_lbl\n",
        "\n",
        "_eval_result = evaluate(_model, _dummy_episode_fn, n_way=5, k_shot=1,\n",
        "                        n_query=15, n_episodes=50)\n",
        "print(f\"Accuracy: {_eval_result['mean_acc']*100:.2f} ± \"\n",
        "      f\"{_eval_result['ci_95']*100:.2f}% (95% CI)\")\n",
        "print(f\"Avg density: {_eval_result['avg_density']:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d01fa77c",
      "metadata": {
        "id": "d01fa77c"
      },
      "source": [
        "## Section 14: Synthetic Graph Recovery Experiment (Section 2.3)\n",
        "\n",
        "Planted-partition protocol: noise level $\\sigma$ calibrated so k-NN achieves ~65% Graph F1, leaving room for DEKAE to demonstrate genuine topology recovery."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7288d4f0",
      "metadata": {
        "id": "7288d4f0"
      },
      "outputs": [],
      "source": [
        "# ── Section 14: Synthetic Graph Recovery Experiment ──────────────────────────\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "def topology_recovery_metrics(A_pred: torch.Tensor,\n",
        "                               A_star: torch.Tensor) -> dict:\n",
        "    \"\"\"\n",
        "    Compare predicted adjacency against ground-truth planted adjacency.\n",
        "    Binarises A_pred at 0.5 threshold.\n",
        "    \"\"\"\n",
        "    A_pred_bin = (A_pred > 0.5).float()\n",
        "    # Remove diagonal\n",
        "    N = A_pred.size(0)\n",
        "    mask = 1 - torch.eye(N, device=A_pred.device)\n",
        "    p = A_pred_bin[mask.bool()].cpu().numpy()\n",
        "    g = A_star[mask.bool()].cpu().numpy()\n",
        "\n",
        "    precision = precision_score(g, p, zero_division=0)\n",
        "    recall    = recall_score(g, p, zero_division=0)\n",
        "    f1        = f1_score(g, p, zero_division=0)\n",
        "    return {\"edge_precision\": precision, \"edge_recall\": recall, \"graph_f1\": f1}\n",
        "\n",
        "\n",
        "def knn_recovery_baseline(X: torch.Tensor, A_star: torch.Tensor, k: int):\n",
        "    \"\"\"Run static k-NN and measure topology recovery.\"\"\"\n",
        "    A_knn = build_knn_adjacency(X, k=k)\n",
        "    return topology_recovery_metrics(A_knn, A_star)\n",
        "\n",
        "\n",
        "def synthetic_recovery_experiment(n_way=5, n_per_class=5, feat_dim=64,\n",
        "                                   sigma_values=(0.3, 0.6, 0.8, 1.0),\n",
        "                                   n_trials=50, knn_k=5):\n",
        "    \"\"\"\n",
        "    Run the topology-recovery experiment across multiple noise levels.\n",
        "    Returns a pandas DataFrame for easy tabulating.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        import pandas as pd\n",
        "        results = []\n",
        "        for sigma in sigma_values:\n",
        "            knn_f1s, ours_f1s = [], []\n",
        "            for _ in range(n_trials):\n",
        "                X, y, A_star = synthetic_episode(\n",
        "                    n_way=n_way, n_nodes_per_class=n_per_class,\n",
        "                    feat_dim=feat_dim, sigma=sigma)\n",
        "\n",
        "                # k-NN baseline\n",
        "                knn_met   = knn_recovery_baseline(X, A_star, k=knn_k)\n",
        "                knn_f1s.append(knn_met[\"graph_f1\"])\n",
        "\n",
        "                # DEKAE topology recovery (single forward pass, no labels – unsupervised topology signal)\n",
        "                A_init  = build_knn_adjacency(X, k=knn_k)\n",
        "                eim     = EdgeIncidenceModule(feat_dim, feat_dim).to(X.device)\n",
        "                dtm     = DynamicTopologyModule(feat_dim, rank=8, edge_dim=feat_dim).to(X.device)\n",
        "                E_, src_, dst_ = eim(X, A_init)\n",
        "                A_dek, _ = dtm(X, E_, src_, dst_, sparsity_reg=False)\n",
        "                ours_met  = topology_recovery_metrics(A_dek.detach(), A_star)\n",
        "                ours_f1s.append(ours_met[\"graph_f1\"])\n",
        "\n",
        "            results.append({\n",
        "                \"sigma\"      : sigma,\n",
        "                \"kNN_F1_mean\": round(np.mean(knn_f1s), 4),\n",
        "                \"kNN_F1_std\" : round(np.std(knn_f1s), 4),\n",
        "                \"DEKAE_F1_mean\": round(np.mean(ours_f1s), 4),\n",
        "                \"DEKAE_F1_std\" : round(np.std(ours_f1s), 4),\n",
        "            })\n",
        "\n",
        "        df = pd.DataFrame(results)\n",
        "        print(df.to_string(index=False))\n",
        "        return df\n",
        "    except ImportError:\n",
        "        print(\"pandas not available — run: !pip install pandas\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# ── Run synthetic experiment ──────────────────────────────────────────────────\n",
        "print(\"Running synthetic topology-recovery experiment …\")\n",
        "df_recovery = synthetic_recovery_experiment(\n",
        "    n_way=5, n_per_class=5, feat_dim=64,\n",
        "    sigma_values=[0.3, 0.6, 0.8, 1.0],\n",
        "    n_trials=30, knn_k=5\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81bc723e",
      "metadata": {
        "id": "81bc723e"
      },
      "source": [
        "## Section 15: Ablation Study Runner\n",
        "\n",
        "Each group (A–G from the plan) can be run by calling `run_ablation(cfg_dict)`. Configs are defined per variant and results collected into a comparison table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f9b5c4b",
      "metadata": {
        "id": "1f9b5c4b"
      },
      "outputs": [],
      "source": [
        "# ── Section 15: Ablation Study Runner ────────────────────────────────────────\n",
        "import copy\n",
        "\n",
        "# ── Base config (derived from CFG) ───────────────────────────────────────────\n",
        "BASE = copy.deepcopy(CFG)\n",
        "BASE[\"n_epochs\"]          = 30    # shorter for ablation sweeps\n",
        "BASE[\"n_episodes_train\"]  = 100\n",
        "BASE[\"n_eval_episodes\"]   = 100\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────────────────────\n",
        "# Group A: Topology Dynamics\n",
        "# ──────────────────────────────────────────────────────────────────────────────\n",
        "ABLATION_CONFIGS = {\n",
        "\n",
        "    # A1 — FSAKE baseline (static k-NN, no edge loss)\n",
        "    \"A1_FSAKE\": {**BASE,\n",
        "        \"use_dynamic\": False, \"lambda_edge\": 0.0, \"sparsity_mode\": \"none\"},\n",
        "\n",
        "    # A2 — Dynamic rewiring only (no edge-to-node loss)\n",
        "    \"A2_dyn_only\": {**BASE,\n",
        "        \"use_dynamic\": True, \"lambda_edge\": 0.0},\n",
        "\n",
        "    # A3 — Dynamic + edge-to-node projection (no edge loss)\n",
        "    \"A3_dyn_proj\": {**BASE,\n",
        "        \"use_dynamic\": True, \"lambda_edge\": 0.0},\n",
        "\n",
        "    # A4 — Full DEKAE model\n",
        "    \"A4_DEKAE_full\": {**BASE,\n",
        "        \"use_dynamic\": True, \"lambda_edge\": 0.5},\n",
        "\n",
        "    # ── Group B: Variable Degree ──────────────────────────────────────────────\n",
        "    \"B1_fixed_k5\":  {**BASE, \"use_dynamic\": False, \"topk_k\": 5,  \"lambda_edge\": 0.0},\n",
        "    \"B2_fixed_k10\": {**BASE, \"use_dynamic\": False, \"topk_k\": 10, \"lambda_edge\": 0.0},\n",
        "    \"B3_dynamic\":   {**BASE, \"use_dynamic\": True,  \"lambda_edge\": 0.5},\n",
        "\n",
        "    # ── Group E: Sparsity ─────────────────────────────────────────────────────\n",
        "    \"E1_no_sparse\":   {**BASE, \"sparsity_mode\": \"none\"},\n",
        "    \"E2_l1\":          {**BASE, \"sparsity_mode\": \"l1\"},\n",
        "    \"E3_topk\":        {**BASE, \"sparsity_mode\": \"topk\"},\n",
        "    \"E4_laplacian\":   {**BASE, \"sparsity_mode\": \"laplacian\"},\n",
        "\n",
        "    # ── Group F: Edge MLP Capacity ────────────────────────────────────────────\n",
        "    # (rank controls capacity; full MLP via larger hidden handled in model)\n",
        "    \"F1_full_rank64\": {**BASE, \"rank\": 64},\n",
        "    \"F2_lowrank16\":   {**BASE, \"rank\": 16},\n",
        "    \"F3_dotprod1\":    {**BASE, \"rank\": 1},\n",
        "\n",
        "    # ── Group G4: Lambda_edge Sensitivity ────────────────────────────────────\n",
        "    \"G4_lam0\":   {**BASE, \"lambda_edge\": 0.0},\n",
        "    \"G4_lam01\":  {**BASE, \"lambda_edge\": 0.1},\n",
        "    \"G4_lam05\":  {**BASE, \"lambda_edge\": 0.5},\n",
        "    \"G4_lam1\":   {**BASE, \"lambda_edge\": 1.0},\n",
        "    \"G4_lam2\":   {**BASE, \"lambda_edge\": 2.0},\n",
        "}\n",
        "\n",
        "\n",
        "def run_ablation(name: str, cfg: dict, episode_fn_train, episode_fn_val,\n",
        "                 log_wandb: bool = False):\n",
        "    \"\"\"\n",
        "    Train and evaluate a single ablation variant.\n",
        "    Returns a summary dict with name, mean_acc, ci_95.\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Running ablation: {name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    set_seed(cfg.get(\"seed\", 42))\n",
        "\n",
        "    model  = build_model(cfg)\n",
        "    model.set_use_dynamic(cfg.get(\"use_dynamic\", True))\n",
        "\n",
        "    # quick train\n",
        "    trained_model, history = train(\n",
        "        cfg, episode_fn_train, episode_fn_val,\n",
        "        run_name=name, log_wandb=log_wandb\n",
        "    )\n",
        "\n",
        "    # evaluate\n",
        "    res = evaluate(trained_model, episode_fn_val,\n",
        "                   cfg[\"n_way\"], cfg[\"k_shot\"], cfg[\"n_query\"],\n",
        "                   n_episodes=cfg.get(\"n_eval_episodes\", 200))\n",
        "    res[\"name\"] = name\n",
        "    print(f\"→ {name}: {res['mean_acc']*100:.2f} ± {res['ci_95']*100:.2f}%\")\n",
        "    return res\n",
        "\n",
        "\n",
        "def run_all_ablations(groups: list, episode_fn_train, episode_fn_val):\n",
        "    \"\"\"Run a subset of ablation groups and collect results.\"\"\"\n",
        "    results = []\n",
        "    for name in groups:\n",
        "        if name not in ABLATION_CONFIGS:\n",
        "            print(f\"⚠ Unknown ablation key: {name}\")\n",
        "            continue\n",
        "        res = run_ablation(name, ABLATION_CONFIGS[name],\n",
        "                           episode_fn_train, episode_fn_val)\n",
        "        results.append(res)\n",
        "    return results\n",
        "\n",
        "\n",
        "print(\"Ablation configs defined.\")\n",
        "print(\"Group A variants :\", [k for k in ABLATION_CONFIGS if k.startswith(\"A\")])\n",
        "print(\"Group E variants :\", [k for k in ABLATION_CONFIGS if k.startswith(\"E\")])\n",
        "print(\"Group G4 variants:\", [k for k in ABLATION_CONFIGS if k.startswith(\"G4\")])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e9c25f4",
      "metadata": {
        "id": "2e9c25f4"
      },
      "source": [
        "## Section 16: Metrics Logging (Weights & Biases)\n",
        "\n",
        "W&B is the recommended logger to survive Colab session disconnects. A JSON backup is saved to Drive at the end of every epoch as a fallback."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a4f0ab1",
      "metadata": {
        "id": "0a4f0ab1"
      },
      "outputs": [],
      "source": [
        "# ── Section 16: Metrics Logging (W&B) ────────────────────────────────────────\n",
        "# Run this cell to initialise W&B before calling train().\n",
        "# Set LOG_WANDB=True in train() call to enable cloud sync.\n",
        "\n",
        "try:\n",
        "    import wandb\n",
        "\n",
        "    WANDB_PROJECT = \"DEKAE-FSL\"\n",
        "    WANDB_ENTITY  = None          # ← set to your W&B username/team if needed\n",
        "\n",
        "    def init_wandb(run_name: str = \"dekae_run\", cfg: dict = None):\n",
        "        wandb.init(\n",
        "            project = WANDB_PROJECT,\n",
        "            entity  = WANDB_ENTITY,\n",
        "            name    = run_name,\n",
        "            config  = cfg or CFG,\n",
        "            resume  = \"allow\",    # resume if run_id matches previous session\n",
        "        )\n",
        "        print(f\"W&B run initialised: {wandb.run.url}\")\n",
        "\n",
        "    # ── Full metrics schema (used by training loop) ───────────────────────────\n",
        "    METRIC_SCHEMA = {\n",
        "        \"train_loss\"         : None,   \"train_acc\"          : None,\n",
        "        \"val_acc\"            : None,   \"test_acc\"           : None,\n",
        "        \"avg_degree\"         : None,   \"degree_std\"         : None,\n",
        "        \"edge_entropy\"       : None,   \"graph_density\"      : None,\n",
        "        \"topology_stability\" : None,   \"intra_edge_ratio\"   : None,\n",
        "        \"inter_edge_ratio\"   : None,   \"layer_repr_stability\": None,\n",
        "        \"grad_norm_mean\"     : None,   \"num_parameters\"     : None,\n",
        "        \"epoch_time_s\"       : None,   \"lambda_edge_scale\"  : None,\n",
        "    }\n",
        "\n",
        "    print(\"W&B available. Call init_wandb('run_name') before train().\")\n",
        "    print(\"Metric keys:\", list(METRIC_SCHEMA.keys()))\n",
        "\n",
        "except ImportError:\n",
        "    print(\"W&B not installed. Fallback: JSON logs saved to:\", RESULTS_DIR)\n",
        "\n",
        "# ── Session-disconnect guard: flush & save ────────────────────────────────────\n",
        "def safe_flush(history: list, run_name: str):\n",
        "    \"\"\"Save history to JSON and flush W&B (if active). Call from training loop.\"\"\"\n",
        "    path = RESULTS_DIR / f\"{run_name}_history.json\"\n",
        "    with open(str(path), \"w\") as f:\n",
        "        json.dump(history, f, default=str)\n",
        "    try:\n",
        "        import wandb\n",
        "        if wandb.run is not None:\n",
        "            wandb.save(str(path))\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "\n",
        "print(\"safe_flush() registered.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d370f023",
      "metadata": {
        "id": "d370f023"
      },
      "source": [
        "## Section 17: Visualization Suite\n",
        "\n",
        "Five required plots: (1) topology per GNN layer, (2) degree distribution, (3) graph density curve, (4) t-SNE before/after, (5) degree vs. sample difficulty using margin difficulty $d_i = s_1(i) - s_2(i)$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a94ccea",
      "metadata": {
        "id": "6a94ccea"
      },
      "outputs": [],
      "source": [
        "# ── Section 17: Visualization Suite ──────────────────────────────────────────\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import seaborn as sns\n",
        "import networkx as nx\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "sns.set_theme(style=\"whitegrid\", font_scale=1.1)\n",
        "SAVE_DIR = RESULTS_DIR / \"figures\"\n",
        "SAVE_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "\n",
        "# ── Plot 1: Graph Topology per GNN Layer ─────────────────────────────────────\n",
        "\n",
        "def plot_topology(A: torch.Tensor, labels: torch.Tensor, title: str = \"\",\n",
        "                  save_path=None):\n",
        "    \"\"\"Visualise an episode graph coloured by class label.\"\"\"\n",
        "    N = A.size(0)\n",
        "    A_np = (A > 0.01).float().cpu().numpy()\n",
        "    G    = nx.from_numpy_array(A_np)\n",
        "\n",
        "    label_list = labels.cpu().tolist()\n",
        "    cmap = plt.cm.get_cmap(\"tab10\", max(label_list) + 1)\n",
        "    colors = [cmap(l) for l in label_list]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(6, 5))\n",
        "    pos = nx.spring_layout(G, seed=42)\n",
        "    nx.draw_networkx(G, pos, node_color=colors,\n",
        "                     with_labels=False, node_size=120,\n",
        "                     edge_color=\"#aaa\", width=0.6, ax=ax)\n",
        "    ax.set_title(title)\n",
        "    plt.tight_layout()\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=120)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# ── Plot 2: Degree Distribution Histogram ─────────────────────────────────────\n",
        "\n",
        "def plot_degree_distribution(A: torch.Tensor, title: str = \"\", save_path=None):\n",
        "    A_no_diag = A.clone(); A_no_diag.fill_diagonal_(0)\n",
        "    degrees = (A_no_diag > 0).float().sum(dim=1).cpu().numpy()\n",
        "    fig, ax = plt.subplots(figsize=(5, 3))\n",
        "    ax.hist(degrees, bins=range(int(degrees.max()) + 2),\n",
        "            color=\"steelblue\", edgecolor=\"white\")\n",
        "    ax.set_xlabel(\"Node Degree\")\n",
        "    ax.set_ylabel(\"Count\")\n",
        "    ax.set_title(title or \"Degree Distribution\")\n",
        "    plt.tight_layout()\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=120)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# ── Plot 3: Graph Density Curve over Training ─────────────────────────────────\n",
        "\n",
        "def plot_density_curve(history: list, save_path=None):\n",
        "    epochs    = [h[\"epoch\"] for h in history]\n",
        "    densities = [h.get(\"graph_density\", 0) for h in history]\n",
        "    fig, ax   = plt.subplots(figsize=(6, 3))\n",
        "    ax.plot(epochs, densities, color=\"coral\", linewidth=2)\n",
        "    ax.axhline(0.5, ls=\"--\", color=\"red\", alpha=0.6, label=\"Collapse threshold (0.5)\")\n",
        "    ax.set_xlabel(\"Epoch\")\n",
        "    ax.set_ylabel(\"Graph Density\")\n",
        "    ax.set_title(\"Graph Density over Training (monitor for collapse)\")\n",
        "    ax.legend()\n",
        "    plt.tight_layout()\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=120)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# ── Plot 4: t-SNE Before / After Dynamic Topology ────────────────────────────\n",
        "\n",
        "def plot_tsne(H_before: torch.Tensor, H_after: torch.Tensor,\n",
        "              labels: torch.Tensor, save_path=None):\n",
        "    H_all  = torch.cat([H_before, H_after], dim=0).cpu().detach().numpy()\n",
        "    labels_np = labels.cpu().numpy()\n",
        "    tsne   = TSNE(n_components=2, perplexity=15, random_state=42)\n",
        "    emb    = tsne.fit_transform(H_all)\n",
        "    N      = H_before.size(0)\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
        "    for ax, title, start, end in zip(\n",
        "            axes,\n",
        "            [\"Before (H⁰)\", \"After Dynamic Topology (Hᴸ)\"],\n",
        "            [0, N], [N, 2 * N]):\n",
        "        sc = ax.scatter(emb[start:end, 0], emb[start:end, 1],\n",
        "                        c=labels_np, cmap=\"tab10\", s=40, alpha=0.8)\n",
        "        ax.set_title(title); ax.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=120)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# ── Plot 5: Node Degree vs. Sample Difficulty ─────────────────────────────────\n",
        "\n",
        "def plot_degree_vs_difficulty(model: DEKAEModel, episode_fn,\n",
        "                               n_way: int, k_shot: int, n_query: int,\n",
        "                               n_episodes: int = 600, save_path=None):\n",
        "    \"\"\"\n",
        "    Bin query nodes into easy / medium / hard tertiles by margin difficulty\n",
        "    d_i = s1(i) - s2(i)  (smaller margin = harder sample).\n",
        "    Show median node degree per bin with 95% CI error bars.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    margin_diffs, degrees = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in tqdm(range(n_episodes), desc=\"Difficulty analysis\"):\n",
        "            s_imgs, s_lbl, q_imgs, q_lbl = episode_fn(n_way, k_shot, n_query)\n",
        "            s_imgs = s_imgs.to(DEVICE); s_lbl = s_lbl.to(DEVICE)\n",
        "            q_imgs = q_imgs.to(DEVICE)\n",
        "\n",
        "            logits, _, mets = model(s_imgs, s_lbl, q_imgs)\n",
        "\n",
        "            # Margin difficulty: difference between top-2 cosine similarities\n",
        "            sorted_logits, _ = logits.sort(dim=1, descending=True)\n",
        "            margin = (sorted_logits[:, 0] - sorted_logits[:, 1]).cpu().numpy()\n",
        "            margin_diffs.extend(margin.tolist())\n",
        "\n",
        "            # Per-query node degree from last A' (approximate via avg_degree here)\n",
        "            # For a precise version, expose per-node degree from forward pass\n",
        "            avg_d = mets.get(\"avg_degree\", 0)\n",
        "            degrees.extend([avg_d] * logits.size(0))\n",
        "\n",
        "    margin_arr  = np.array(margin_diffs)\n",
        "    degree_arr  = np.array(degrees)\n",
        "\n",
        "    tertile1, tertile2 = np.percentile(margin_arr, [33, 66])\n",
        "    bins = {\"Hard\\n(low margin)\"  : degree_arr[margin_arr <= tertile1],\n",
        "            \"Medium\"              : degree_arr[(margin_arr > tertile1) & (margin_arr <= tertile2)],\n",
        "            \"Easy\\n(high margin)\" : degree_arr[margin_arr > tertile2]}\n",
        "\n",
        "    labels_plot  = list(bins.keys())\n",
        "    means  = [np.median(v) for v in bins.values()]\n",
        "    cis    = [1.96 * np.std(v) / max(np.sqrt(len(v)), 1) for v in bins.values()]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(5, 4))\n",
        "    ax.bar(labels_plot, means, yerr=cis, color=[\"#e74c3c\", \"#f39c12\", \"#2ecc71\"],\n",
        "           capsize=6, edgecolor=\"white\")\n",
        "    ax.set_ylabel(\"Average Node Degree\")\n",
        "    ax.set_title(\"Node Degree vs. Sample Difficulty\\n(Hard samples → more neighbours)\")\n",
        "    plt.tight_layout()\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=120)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# ── Demo: run all plots on the toy model ─────────────────────────────────────\n",
        "\n",
        "# Plot 1 — topology\n",
        "_labels_demo = torch.cat([torch.full((4,), c) for c in range(5)]).to(DEVICE)\n",
        "plot_topology(_A_dyn, _labels_demo, title=\"Episode Topology (Layer 3)\",\n",
        "              save_path=str(SAVE_DIR / \"topology_layer3.png\"))\n",
        "\n",
        "# Plot 2 — degree distribution\n",
        "plot_degree_distribution(_A_dyn, \"Degree Distribution (DEKAE)\",\n",
        "                         save_path=str(SAVE_DIR / \"degree_dist.png\"))\n",
        "\n",
        "# Plot 3 — density curve (requires history from train())\n",
        "# Uncomment after running train():\n",
        "# plot_density_curve(history, save_path=str(SAVE_DIR / \"density_curve.png\"))\n",
        "\n",
        "# Plot 4 — t-SNE (requires H_before, H_after, labels from a real forward pass)\n",
        "print(\"Plots 3/4/5 require training history & real data — run after train().\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "G4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}